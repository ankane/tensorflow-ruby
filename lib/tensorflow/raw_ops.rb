# Generated by `rake generate_ops`
module Tensorflow
  module RawOps
    class << self
      def abort(error_msg: nil, exit_without_error: nil)
        Context.default.execute("Abort", [], error_msg: error_msg, exit_without_error: exit_without_error)
      end

      def abs(x: nil)
        Context.default.execute("Abs", [x])
      end

      def accumulate_nv2(inputs: nil, shape: nil)
        Context.default.execute("AccumulateNV2", [inputs], shape: shape)
      end

      def accumulator_apply_gradient(handle: nil, local_step: nil, gradient: nil, dtype: nil)
        Context.default.execute("AccumulatorApplyGradient", [handle, local_step, gradient], dtype: dtype)
      end

      def accumulator_num_accumulated(handle: nil)
        Context.default.execute("AccumulatorNumAccumulated", [handle])
      end

      def accumulator_set_global_step(handle: nil, new_global_step: nil)
        Context.default.execute("AccumulatorSetGlobalStep", [handle, new_global_step])
      end

      def accumulator_take_gradient(handle: nil, num_required: nil, dtype: nil)
        Context.default.execute("AccumulatorTakeGradient", [handle, num_required], dtype: dtype)
      end

      def acos(x: nil)
        Context.default.execute("Acos", [x])
      end

      def acosh(x: nil)
        Context.default.execute("Acosh", [x])
      end

      def add(x: nil, y: nil)
        Context.default.execute("Add", [x, y])
      end

      def add_many_sparse_to_tensors_map(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, container: nil, shared_name: nil)
        Context.default.execute("AddManySparseToTensorsMap", [sparse_indices, sparse_values, sparse_shape], container: container, shared_name: shared_name)
      end

      def add_n(inputs: nil)
        Context.default.execute("AddN", [inputs])
      end

      def add_sparse_to_tensors_map(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, container: nil, shared_name: nil)
        Context.default.execute("AddSparseToTensorsMap", [sparse_indices, sparse_values, sparse_shape], container: container, shared_name: shared_name)
      end

      def add_v2(x: nil, y: nil)
        Context.default.execute("AddV2", [x, y])
      end

      def adjust_contrast(images: nil, contrast_factor: nil, min_value: nil, max_value: nil)
        Context.default.execute("AdjustContrast", [images, contrast_factor, min_value, max_value])
      end

      def adjust_contrastv2(images: nil, contrast_factor: nil)
        Context.default.execute("AdjustContrastv2", [images, contrast_factor])
      end

      def adjust_hue(images: nil, delta: nil)
        Context.default.execute("AdjustHue", [images, delta])
      end

      def adjust_saturation(images: nil, scale: nil)
        Context.default.execute("AdjustSaturation", [images, scale])
      end

      def all(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("All", [input, reduction_indices], keep_dims: keep_dims)
      end

      def all_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, seed: nil, seed2: nil)
        Context.default.execute("AllCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, seed: seed, seed2: seed2)
      end

      def all_to_all(input: nil, group_assignment: nil, concat_dimension: nil, split_dimension: nil, split_count: nil)
        Context.default.execute("AllToAll", [input, group_assignment], concat_dimension: concat_dimension, split_dimension: split_dimension, split_count: split_count)
      end

      def angle(input: nil)
        Context.default.execute("Angle", [input])
      end

      def anonymous_iterator(output_types: nil, output_shapes: nil)
        Context.default.execute("AnonymousIterator", [], output_types: output_types, output_shapes: output_shapes)
      end

      def anonymous_iterator_v2(output_types: nil, output_shapes: nil)
        Context.default.execute("AnonymousIteratorV2", [], output_types: output_types, output_shapes: output_shapes)
      end

      def any(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("Any", [input, reduction_indices], keep_dims: keep_dims)
      end

      def apply_ada_max(var: nil, m: nil, v: nil, beta1_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyAdaMax", [var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking)
      end

      def apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad], use_locking: use_locking)
      end

      def apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, use_locking: nil, update_slots: nil)
        Context.default.execute("ApplyAdagrad", [var, accum, lr, grad], use_locking: use_locking, update_slots: update_slots)
      end

      def apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
        Context.default.execute("ApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step], use_locking: use_locking)
      end

      def apply_adam(var: nil, m: nil, v: nil, beta1_power: nil, beta2_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ApplyAdam", [var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def apply_add_sign(var: nil, m: nil, lr: nil, alpha: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyAddSign", [var, m, lr, alpha, sign_decay, beta, grad], use_locking: use_locking)
      end

      def apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
      end

      def apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("ApplyFtrl", [var, accum, linear, grad, lr, l1, l2, lr_power], use_locking: use_locking)
      end

      def apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("ApplyFtrlV2", [var, accum, linear, grad, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
      end

      def apply_gradient_descent(var: nil, alpha: nil, delta: nil, use_locking: nil)
        Context.default.execute("ApplyGradientDescent", [var, alpha, delta], use_locking: use_locking)
      end

      def apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ApplyMomentum", [var, accum, lr, grad, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def apply_power_sign(var: nil, m: nil, lr: nil, logbase: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyPowerSign", [var, m, lr, logbase, sign_decay, beta, grad], use_locking: use_locking)
      end

      def apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyProximalAdagrad", [var, accum, lr, l1, l2, grad], use_locking: use_locking)
      end

      def apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, delta: nil, use_locking: nil)
        Context.default.execute("ApplyProximalGradientDescent", [var, alpha, l1, l2, delta], use_locking: use_locking)
      end

      def apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
      end

      def approximate_equal(x: nil, y: nil, tolerance: nil)
        Context.default.execute("ApproximateEqual", [x, y], tolerance: tolerance)
      end

      def arg_max(input: nil, dimension: nil, output_type: nil)
        Context.default.execute("ArgMax", [input, dimension], output_type: output_type)
      end

      def arg_min(input: nil, dimension: nil, output_type: nil)
        Context.default.execute("ArgMin", [input, dimension], output_type: output_type)
      end

      def as_string(input: nil, precision: nil, scientific: nil, shortest: nil, width: nil, fill: nil)
        Context.default.execute("AsString", [input], precision: precision, scientific: scientific, shortest: shortest, width: width, fill: fill)
      end

      def asin(x: nil)
        Context.default.execute("Asin", [x])
      end

      def asinh(x: nil)
        Context.default.execute("Asinh", [x])
      end

      def assert(condition: nil, data: nil, summarize: nil)
        Context.default.execute("Assert", [condition, data], summarize: summarize)
      end

      def assign(ref: nil, value: nil, validate_shape: nil, use_locking: nil)
        Context.default.execute("Assign", [ref, value], validate_shape: validate_shape, use_locking: use_locking)
      end

      def assign_add(ref: nil, value: nil, use_locking: nil)
        Context.default.execute("AssignAdd", [ref, value], use_locking: use_locking)
      end

      def assign_add_variable_op(resource: nil, value: nil, dtype: nil)
        Context.default.execute("AssignAddVariableOp", [resource, value], dtype: dtype)
      end

      def assign_sub(ref: nil, value: nil, use_locking: nil)
        Context.default.execute("AssignSub", [ref, value], use_locking: use_locking)
      end

      def assign_sub_variable_op(resource: nil, value: nil, dtype: nil)
        Context.default.execute("AssignSubVariableOp", [resource, value], dtype: dtype)
      end

      def assign_variable_op(resource: nil, value: nil, dtype: nil)
        Context.default.execute("AssignVariableOp", [resource, value], dtype: dtype)
      end

      def atan(x: nil)
        Context.default.execute("Atan", [x])
      end

      def atan2(y: nil, x: nil)
        Context.default.execute("Atan2", [y, x])
      end

      def atanh(x: nil)
        Context.default.execute("Atanh", [x])
      end

      def audio_spectrogram(input: nil, window_size: nil, stride: nil, magnitude_squared: nil)
        Context.default.execute("AudioSpectrogram", [input], window_size: window_size, stride: stride, magnitude_squared: magnitude_squared)
      end

      def audio_summary(tag: nil, tensor: nil, sample_rate: nil, max_outputs: nil)
        Context.default.execute("AudioSummary", [tag, tensor], sample_rate: sample_rate, max_outputs: max_outputs)
      end

      def audio_summary_v2(tag: nil, tensor: nil, sample_rate: nil, max_outputs: nil)
        Context.default.execute("AudioSummaryV2", [tag, tensor, sample_rate], max_outputs: max_outputs)
      end

      def avg_pool(value: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("AvgPool", [value], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def avg_pool3d(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("AvgPool3D", [input], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def avg_pool3d_grad(orig_input_shape: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("AvgPool3DGrad", [orig_input_shape, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def avg_pool_grad(orig_input_shape: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("AvgPoolGrad", [orig_input_shape, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def barrier(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("Barrier", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def barrier_close(handle: nil, cancel_pending_enqueues: nil)
        Context.default.execute("BarrierClose", [handle], cancel_pending_enqueues: cancel_pending_enqueues)
      end

      def barrier_incomplete_size(handle: nil)
        Context.default.execute("BarrierIncompleteSize", [handle])
      end

      def barrier_insert_many(handle: nil, keys: nil, values: nil, component_index: nil)
        Context.default.execute("BarrierInsertMany", [handle, keys, values], component_index: component_index)
      end

      def barrier_ready_size(handle: nil)
        Context.default.execute("BarrierReadySize", [handle])
      end

      def barrier_take_many(handle: nil, num_elements: nil, component_types: nil, allow_small_batch: nil, wait_for_incomplete: nil, timeout_ms: nil)
        Context.default.execute("BarrierTakeMany", [handle, num_elements], component_types: component_types, allow_small_batch: allow_small_batch, wait_for_incomplete: wait_for_incomplete, timeout_ms: timeout_ms)
      end

      def batch(in_tensors: nil, num_batch_threads: nil, max_batch_size: nil, max_enqueued_batches: nil, batch_timeout_micros: nil, allowed_batch_sizes: nil, grad_timeout_micros: nil, container: nil, shared_name: nil, batching_queue: nil)
        Context.default.execute("Batch", [in_tensors], num_batch_threads: num_batch_threads, max_batch_size: max_batch_size, max_enqueued_batches: max_enqueued_batches, batch_timeout_micros: batch_timeout_micros, allowed_batch_sizes: allowed_batch_sizes, grad_timeout_micros: grad_timeout_micros, container: container, shared_name: shared_name, batching_queue: batching_queue)
      end

      def batch_cholesky(input: nil)
        Context.default.execute("BatchCholesky", [input])
      end

      def batch_cholesky_grad(l: nil, grad: nil)
        Context.default.execute("BatchCholeskyGrad", [l, grad])
      end

      def batch_dataset(input_dataset: nil, batch_size: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("BatchDataset", [input_dataset, batch_size], output_types: output_types, output_shapes: output_shapes)
      end

      def batch_dataset_v2(input_dataset: nil, batch_size: nil, drop_remainder: nil, parallel_copy: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("BatchDatasetV2", [input_dataset, batch_size, drop_remainder], parallel_copy: parallel_copy, output_types: output_types, output_shapes: output_shapes)
      end

      def batch_fft(input: nil)
        Context.default.execute("BatchFFT", [input])
      end

      def batch_fft2d(input: nil)
        Context.default.execute("BatchFFT2D", [input])
      end

      def batch_fft3d(input: nil)
        Context.default.execute("BatchFFT3D", [input])
      end

      def batch_function(in_tensors: nil, captured_tensors: nil, f: nil, num_batch_threads: nil, max_batch_size: nil, batch_timeout_micros: nil, max_enqueued_batches: nil, allowed_batch_sizes: nil, container: nil, shared_name: nil, batching_queue: nil)
        Context.default.execute("BatchFunction", [in_tensors, captured_tensors], f: f, num_batch_threads: num_batch_threads, max_batch_size: max_batch_size, batch_timeout_micros: batch_timeout_micros, max_enqueued_batches: max_enqueued_batches, allowed_batch_sizes: allowed_batch_sizes, container: container, shared_name: shared_name, batching_queue: batching_queue)
      end

      def batch_ifft(input: nil)
        Context.default.execute("BatchIFFT", [input])
      end

      def batch_ifft2d(input: nil)
        Context.default.execute("BatchIFFT2D", [input])
      end

      def batch_ifft3d(input: nil)
        Context.default.execute("BatchIFFT3D", [input])
      end

      def batch_mat_mul(x: nil, y: nil, adj_x: nil, adj_y: nil)
        Context.default.execute("BatchMatMul", [x, y], adj_x: adj_x, adj_y: adj_y)
      end

      def batch_mat_mul_v2(x: nil, y: nil, adj_x: nil, adj_y: nil)
        Context.default.execute("BatchMatMulV2", [x, y], adj_x: adj_x, adj_y: adj_y)
      end

      def batch_matrix_band_part(input: nil, num_lower: nil, num_upper: nil)
        Context.default.execute("BatchMatrixBandPart", [input, num_lower, num_upper])
      end

      def batch_matrix_determinant(input: nil)
        Context.default.execute("BatchMatrixDeterminant", [input])
      end

      def batch_matrix_diag(diagonal: nil)
        Context.default.execute("BatchMatrixDiag", [diagonal])
      end

      def batch_matrix_diag_part(input: nil)
        Context.default.execute("BatchMatrixDiagPart", [input])
      end

      def batch_matrix_inverse(input: nil, adjoint: nil)
        Context.default.execute("BatchMatrixInverse", [input], adjoint: adjoint)
      end

      def batch_matrix_set_diag(input: nil, diagonal: nil)
        Context.default.execute("BatchMatrixSetDiag", [input, diagonal])
      end

      def batch_matrix_solve(matrix: nil, rhs: nil, adjoint: nil)
        Context.default.execute("BatchMatrixSolve", [matrix, rhs], adjoint: adjoint)
      end

      def batch_matrix_solve_ls(matrix: nil, rhs: nil, l2_regularizer: nil, fast: nil)
        Context.default.execute("BatchMatrixSolveLs", [matrix, rhs, l2_regularizer], fast: fast)
      end

      def batch_matrix_triangular_solve(matrix: nil, rhs: nil, lower: nil, adjoint: nil)
        Context.default.execute("BatchMatrixTriangularSolve", [matrix, rhs], lower: lower, adjoint: adjoint)
      end

      def batch_norm_with_global_normalization(t: nil, m: nil, v: nil, beta: nil, gamma: nil, variance_epsilon: nil, scale_after_normalization: nil)
        Context.default.execute("BatchNormWithGlobalNormalization", [t, m, v, beta, gamma], variance_epsilon: variance_epsilon, scale_after_normalization: scale_after_normalization)
      end

      def batch_norm_with_global_normalization_grad(t: nil, m: nil, v: nil, gamma: nil, backprop: nil, variance_epsilon: nil, scale_after_normalization: nil)
        Context.default.execute("BatchNormWithGlobalNormalizationGrad", [t, m, v, gamma, backprop], variance_epsilon: variance_epsilon, scale_after_normalization: scale_after_normalization)
      end

      def batch_self_adjoint_eig(input: nil)
        Context.default.execute("BatchSelfAdjointEig", [input])
      end

      def batch_self_adjoint_eig_v2(input: nil, compute_v: nil)
        Context.default.execute("BatchSelfAdjointEigV2", [input], compute_v: compute_v)
      end

      def batch_svd(input: nil, compute_uv: nil, full_matrices: nil)
        Context.default.execute("BatchSvd", [input], compute_uv: compute_uv, full_matrices: full_matrices)
      end

      def batch_to_space(input: nil, crops: nil, block_size: nil)
        Context.default.execute("BatchToSpace", [input, crops], block_size: block_size)
      end

      def batch_to_space_nd(input: nil, block_shape: nil, crops: nil)
        Context.default.execute("BatchToSpaceND", [input, block_shape, crops])
      end

      def bessel_i0e(x: nil)
        Context.default.execute("BesselI0e", [x])
      end

      def bessel_i1e(x: nil)
        Context.default.execute("BesselI1e", [x])
      end

      def betainc(a: nil, b: nil, x: nil)
        Context.default.execute("Betainc", [a, b, x])
      end

      def bias_add(value: nil, bias: nil, data_format: nil)
        Context.default.execute("BiasAdd", [value, bias], data_format: data_format)
      end

      def bias_add_grad(out_backprop: nil, data_format: nil)
        Context.default.execute("BiasAddGrad", [out_backprop], data_format: data_format)
      end

      def bias_add_v1(value: nil, bias: nil)
        Context.default.execute("BiasAddV1", [value, bias])
      end

      def big_query_reader(container: nil, shared_name: nil, project_id: nil, dataset_id: nil, table_id: nil, columns: nil, timestamp_millis: nil, test_end_point: nil)
        Context.default.execute("BigQueryReader", [], container: container, shared_name: shared_name, project_id: project_id, dataset_id: dataset_id, table_id: table_id, columns: columns, timestamp_millis: timestamp_millis, test_end_point: test_end_point)
      end

      def bincount(arr: nil, size: nil, weights: nil)
        Context.default.execute("Bincount", [arr, size, weights])
      end

      def bitcast(input: nil, type: nil)
        Context.default.execute("Bitcast", [input], type: type)
      end

      def bitwise_and(x: nil, y: nil)
        Context.default.execute("BitwiseAnd", [x, y])
      end

      def bitwise_or(x: nil, y: nil)
        Context.default.execute("BitwiseOr", [x, y])
      end

      def bitwise_xor(x: nil, y: nil)
        Context.default.execute("BitwiseXor", [x, y])
      end

      def boosted_trees_aggregate_stats(node_ids: nil, gradients: nil, hessians: nil, feature: nil, max_splits: nil, num_buckets: nil)
        Context.default.execute("BoostedTreesAggregateStats", [node_ids, gradients, hessians, feature], max_splits: max_splits, num_buckets: num_buckets)
      end

      def boosted_trees_bucketize(float_values: nil, bucket_boundaries: nil, num_features: nil)
        Context.default.execute("BoostedTreesBucketize", [float_values, bucket_boundaries], num_features: num_features)
      end

      def boosted_trees_calculate_best_feature_split(node_id_range: nil, stats_summary: nil, l1: nil, l2: nil, tree_complexity: nil, min_node_weight: nil, logits_dimension: nil, split_type: nil)
        Context.default.execute("BoostedTreesCalculateBestFeatureSplit", [node_id_range, stats_summary, l1, l2, tree_complexity, min_node_weight], logits_dimension: logits_dimension, split_type: split_type)
      end

      def boosted_trees_calculate_best_gains_per_feature(node_id_range: nil, stats_summary_list: nil, l1: nil, l2: nil, tree_complexity: nil, min_node_weight: nil, max_splits: nil, num_features: nil)
        Context.default.execute("BoostedTreesCalculateBestGainsPerFeature", [node_id_range, stats_summary_list, l1, l2, tree_complexity, min_node_weight], max_splits: max_splits, num_features: num_features)
      end

      def boosted_trees_center_bias(tree_ensemble_handle: nil, mean_gradients: nil, mean_hessians: nil, l1: nil, l2: nil)
        Context.default.execute("BoostedTreesCenterBias", [tree_ensemble_handle, mean_gradients, mean_hessians, l1, l2])
      end

      def boosted_trees_create_ensemble(tree_ensemble_handle: nil, stamp_token: nil, tree_ensemble_serialized: nil)
        Context.default.execute("BoostedTreesCreateEnsemble", [tree_ensemble_handle, stamp_token, tree_ensemble_serialized])
      end

      def boosted_trees_create_quantile_stream_resource(quantile_stream_resource_handle: nil, epsilon: nil, num_streams: nil, max_elements: nil)
        Context.default.execute("BoostedTreesCreateQuantileStreamResource", [quantile_stream_resource_handle, epsilon, num_streams], max_elements: max_elements)
      end

      def boosted_trees_deserialize_ensemble(tree_ensemble_handle: nil, stamp_token: nil, tree_ensemble_serialized: nil)
        Context.default.execute("BoostedTreesDeserializeEnsemble", [tree_ensemble_handle, stamp_token, tree_ensemble_serialized])
      end

      def boosted_trees_ensemble_resource_handle_op(container: nil, shared_name: nil)
        Context.default.execute("BoostedTreesEnsembleResourceHandleOp", [], container: container, shared_name: shared_name)
      end

      def boosted_trees_example_debug_outputs(tree_ensemble_handle: nil, bucketized_features: nil, num_bucketized_features: nil, logits_dimension: nil)
        Context.default.execute("BoostedTreesExampleDebugOutputs", [tree_ensemble_handle, bucketized_features], num_bucketized_features: num_bucketized_features, logits_dimension: logits_dimension)
      end

      def boosted_trees_get_ensemble_states(tree_ensemble_handle: nil)
        Context.default.execute("BoostedTreesGetEnsembleStates", [tree_ensemble_handle])
      end

      def boosted_trees_make_quantile_summaries(float_values: nil, example_weights: nil, epsilon: nil, num_features: nil)
        Context.default.execute("BoostedTreesMakeQuantileSummaries", [float_values, example_weights, epsilon], num_features: num_features)
      end

      def boosted_trees_make_stats_summary(node_ids: nil, gradients: nil, hessians: nil, bucketized_features_list: nil, max_splits: nil, num_buckets: nil, num_features: nil)
        Context.default.execute("BoostedTreesMakeStatsSummary", [node_ids, gradients, hessians, bucketized_features_list], max_splits: max_splits, num_buckets: num_buckets, num_features: num_features)
      end

      def boosted_trees_predict(tree_ensemble_handle: nil, bucketized_features: nil, num_bucketized_features: nil, logits_dimension: nil)
        Context.default.execute("BoostedTreesPredict", [tree_ensemble_handle, bucketized_features], num_bucketized_features: num_bucketized_features, logits_dimension: logits_dimension)
      end

      def boosted_trees_quantile_stream_resource_add_summaries(quantile_stream_resource_handle: nil, summaries: nil, num_features: nil)
        Context.default.execute("BoostedTreesQuantileStreamResourceAddSummaries", [quantile_stream_resource_handle, summaries], num_features: num_features)
      end

      def boosted_trees_quantile_stream_resource_deserialize(quantile_stream_resource_handle: nil, bucket_boundaries: nil, num_streams: nil)
        Context.default.execute("BoostedTreesQuantileStreamResourceDeserialize", [quantile_stream_resource_handle, bucket_boundaries], num_streams: num_streams)
      end

      def boosted_trees_quantile_stream_resource_flush(quantile_stream_resource_handle: nil, num_buckets: nil, generate_quantiles: nil)
        Context.default.execute("BoostedTreesQuantileStreamResourceFlush", [quantile_stream_resource_handle, num_buckets], generate_quantiles: generate_quantiles)
      end

      def boosted_trees_quantile_stream_resource_get_bucket_boundaries(quantile_stream_resource_handle: nil, num_features: nil)
        Context.default.execute("BoostedTreesQuantileStreamResourceGetBucketBoundaries", [quantile_stream_resource_handle], num_features: num_features)
      end

      def boosted_trees_quantile_stream_resource_handle_op(container: nil, shared_name: nil)
        Context.default.execute("BoostedTreesQuantileStreamResourceHandleOp", [], container: container, shared_name: shared_name)
      end

      def boosted_trees_serialize_ensemble(tree_ensemble_handle: nil)
        Context.default.execute("BoostedTreesSerializeEnsemble", [tree_ensemble_handle])
      end

      def boosted_trees_training_predict(tree_ensemble_handle: nil, cached_tree_ids: nil, cached_node_ids: nil, bucketized_features: nil, num_bucketized_features: nil, logits_dimension: nil)
        Context.default.execute("BoostedTreesTrainingPredict", [tree_ensemble_handle, cached_tree_ids, cached_node_ids, bucketized_features], num_bucketized_features: num_bucketized_features, logits_dimension: logits_dimension)
      end

      def boosted_trees_update_ensemble(tree_ensemble_handle: nil, feature_ids: nil, node_ids: nil, gains: nil, thresholds: nil, left_node_contribs: nil, right_node_contribs: nil, max_depth: nil, learning_rate: nil, pruning_mode: nil, num_features: nil)
        Context.default.execute("BoostedTreesUpdateEnsemble", [tree_ensemble_handle, feature_ids, node_ids, gains, thresholds, left_node_contribs, right_node_contribs, max_depth, learning_rate], pruning_mode: pruning_mode, num_features: num_features)
      end

      def broadcast_args(s0: nil, s1: nil)
        Context.default.execute("BroadcastArgs", [s0, s1])
      end

      def broadcast_gradient_args(s0: nil, s1: nil)
        Context.default.execute("BroadcastGradientArgs", [s0, s1])
      end

      def broadcast_to(input: nil, shape: nil)
        Context.default.execute("BroadcastTo", [input, shape])
      end

      def bucketize(input: nil, boundaries: nil)
        Context.default.execute("Bucketize", [input], boundaries: boundaries)
      end

      def ctc_beam_search_decoder(inputs: nil, sequence_length: nil, beam_width: nil, top_paths: nil, merge_repeated: nil)
        Context.default.execute("CTCBeamSearchDecoder", [inputs, sequence_length], beam_width: beam_width, top_paths: top_paths, merge_repeated: merge_repeated)
      end

      def ctc_greedy_decoder(inputs: nil, sequence_length: nil, merge_repeated: nil)
        Context.default.execute("CTCGreedyDecoder", [inputs, sequence_length], merge_repeated: merge_repeated)
      end

      def ctc_loss(inputs: nil, labels_indices: nil, labels_values: nil, sequence_length: nil, preprocess_collapse_repeated: nil, ctc_merge_repeated: nil, ignore_longer_outputs_than_inputs: nil)
        Context.default.execute("CTCLoss", [inputs, labels_indices, labels_values, sequence_length], preprocess_collapse_repeated: preprocess_collapse_repeated, ctc_merge_repeated: ctc_merge_repeated, ignore_longer_outputs_than_inputs: ignore_longer_outputs_than_inputs)
      end

      def cache_dataset(input_dataset: nil, filename: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("CacheDataset", [input_dataset, filename], output_types: output_types, output_shapes: output_shapes)
      end

      def case(branch_index: nil, input: nil, branches: nil, output_shapes: nil)
        Context.default.execute("Case", [branch_index, input], branches: branches, output_shapes: output_shapes)
      end

      def cast(x: nil)
        Context.default.execute("Cast", [x])
      end

      def ceil(x: nil)
        Context.default.execute("Ceil", [x])
      end

      def check_numerics(tensor: nil, message: nil)
        Context.default.execute("CheckNumerics", [tensor], message: message)
      end

      def cholesky(input: nil)
        Context.default.execute("Cholesky", [input])
      end

      def cholesky_grad(l: nil, grad: nil)
        Context.default.execute("CholeskyGrad", [l, grad])
      end

      def choose_fastest_branch_dataset(input_dataset: nil, ratio_numerator: nil, ratio_denominator: nil, other_arguments: nil, num_elements_per_branch: nil, branches: nil, other_arguments_lengths: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ChooseFastestBranchDataset", [input_dataset, ratio_numerator, ratio_denominator, other_arguments], num_elements_per_branch: num_elements_per_branch, branches: branches, other_arguments_lengths: other_arguments_lengths, output_types: output_types, output_shapes: output_shapes)
      end

      def clip_by_value(t: nil, clip_value_min: nil, clip_value_max: nil)
        Context.default.execute("ClipByValue", [t, clip_value_min, clip_value_max])
      end

      def close_summary_writer(writer: nil)
        Context.default.execute("CloseSummaryWriter", [writer])
      end

      def collective_bcast_recv(group_size: nil, group_key: nil, instance_key: nil, shape: nil)
        Context.default.execute("CollectiveBcastRecv", [], group_size: group_size, group_key: group_key, instance_key: instance_key, shape: shape)
      end

      def collective_bcast_send(input: nil, group_size: nil, group_key: nil, instance_key: nil, shape: nil)
        Context.default.execute("CollectiveBcastSend", [input], group_size: group_size, group_key: group_key, instance_key: instance_key, shape: shape)
      end

      def collective_gather(input: nil, group_size: nil, group_key: nil, instance_key: nil, shape: nil)
        Context.default.execute("CollectiveGather", [input], group_size: group_size, group_key: group_key, instance_key: instance_key, shape: shape)
      end

      def collective_permute(input: nil, source_target_pairs: nil)
        Context.default.execute("CollectivePermute", [input, source_target_pairs])
      end

      def collective_reduce(input: nil, group_size: nil, group_key: nil, instance_key: nil, merge_op: nil, final_op: nil, subdiv_offsets: nil, wait_for: nil)
        Context.default.execute("CollectiveReduce", [input], group_size: group_size, group_key: group_key, instance_key: instance_key, merge_op: merge_op, final_op: final_op, subdiv_offsets: subdiv_offsets, wait_for: wait_for)
      end

      def combined_non_max_suppression(boxes: nil, scores: nil, max_output_size_per_class: nil, max_total_size: nil, iou_threshold: nil, score_threshold: nil, pad_per_class: nil, clip_boxes: nil)
        Context.default.execute("CombinedNonMaxSuppression", [boxes, scores, max_output_size_per_class, max_total_size, iou_threshold, score_threshold], pad_per_class: pad_per_class, clip_boxes: clip_boxes)
      end

      def compare_and_bitpack(input: nil, threshold: nil)
        Context.default.execute("CompareAndBitpack", [input, threshold])
      end

      def complex(real: nil, imag: nil)
        Context.default.execute("Complex", [real, imag])
      end

      def complex_abs(x: nil)
        Context.default.execute("ComplexAbs", [x])
      end

      def compute_accidental_hits(true_classes: nil, sampled_candidates: nil, num_true: nil, seed: nil, seed2: nil)
        Context.default.execute("ComputeAccidentalHits", [true_classes, sampled_candidates], num_true: num_true, seed: seed, seed2: seed2)
      end

      def concat(concat_dim: nil, values: nil)
        Context.default.execute("Concat", [concat_dim, values])
      end

      def concat_offset(concat_dim: nil, shape: nil)
        Context.default.execute("ConcatOffset", [concat_dim, shape])
      end

      def concat_v2(values: nil, axis: nil)
        Context.default.execute("ConcatV2", [values, axis])
      end

      def concatenate_dataset(input_dataset: nil, another_dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ConcatenateDataset", [input_dataset, another_dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def conditional_accumulator(dtype: nil, shape: nil, container: nil, shared_name: nil, reduction_type: nil)
        Context.default.execute("ConditionalAccumulator", [], dtype: dtype, shape: shape, container: container, shared_name: shared_name, reduction_type: reduction_type)
      end

      def configure_distributed_tpu(embedding_config: nil, tpu_embedding_config: nil, is_global_init: nil)
        Context.default.execute("ConfigureDistributedTPU", [], embedding_config: embedding_config, tpu_embedding_config: tpu_embedding_config, is_global_init: is_global_init)
      end

      def conj(input: nil)
        Context.default.execute("Conj", [input])
      end

      def conjugate_transpose(x: nil, perm: nil)
        Context.default.execute("ConjugateTranspose", [x, perm])
      end

      def const(value: nil, dtype: nil)
        Context.default.execute("Const", [], value: value, dtype: dtype)
      end

      def consume_mutex_lock(mutex_lock: nil)
        Context.default.execute("ConsumeMutexLock", [mutex_lock])
      end

      def control_trigger
        Context.default.execute("ControlTrigger", [])
      end

      def conv2d(input: nil, filter: nil, strides: nil, use_cudnn_on_gpu: nil, padding: nil, explicit_paddings: nil, data_format: nil, dilations: nil)
        Context.default.execute("Conv2D", [input, filter], strides: strides, use_cudnn_on_gpu: use_cudnn_on_gpu, padding: padding, explicit_paddings: explicit_paddings, data_format: data_format, dilations: dilations)
      end

      def conv2d_backprop_filter(input: nil, filter_sizes: nil, out_backprop: nil, strides: nil, use_cudnn_on_gpu: nil, padding: nil, explicit_paddings: nil, data_format: nil, dilations: nil)
        Context.default.execute("Conv2DBackpropFilter", [input, filter_sizes, out_backprop], strides: strides, use_cudnn_on_gpu: use_cudnn_on_gpu, padding: padding, explicit_paddings: explicit_paddings, data_format: data_format, dilations: dilations)
      end

      def conv2d_backprop_input(input_sizes: nil, filter: nil, out_backprop: nil, strides: nil, use_cudnn_on_gpu: nil, padding: nil, explicit_paddings: nil, data_format: nil, dilations: nil)
        Context.default.execute("Conv2DBackpropInput", [input_sizes, filter, out_backprop], strides: strides, use_cudnn_on_gpu: use_cudnn_on_gpu, padding: padding, explicit_paddings: explicit_paddings, data_format: data_format, dilations: dilations)
      end

      def conv3d(input: nil, filter: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
        Context.default.execute("Conv3D", [input, filter], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
      end

      def conv3d_backprop_filter(input: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("Conv3DBackpropFilter", [input, filter, out_backprop], strides: strides, padding: padding, dilations: dilations)
      end

      def conv3d_backprop_filter_v2(input: nil, filter_sizes: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
        Context.default.execute("Conv3DBackpropFilterV2", [input, filter_sizes, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
      end

      def conv3d_backprop_input(input: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("Conv3DBackpropInput", [input, filter, out_backprop], strides: strides, padding: padding, dilations: dilations)
      end

      def conv3d_backprop_input_v2(input_sizes: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
        Context.default.execute("Conv3DBackpropInputV2", [input_sizes, filter, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
      end

      def copy(input: nil, tensor_name: nil, debug_ops_spec: nil)
        Context.default.execute("Copy", [input], tensor_name: tensor_name, debug_ops_spec: debug_ops_spec)
      end

      def copy_host(input: nil, tensor_name: nil, debug_ops_spec: nil)
        Context.default.execute("CopyHost", [input], tensor_name: tensor_name, debug_ops_spec: debug_ops_spec)
      end

      def cos(x: nil)
        Context.default.execute("Cos", [x])
      end

      def cosh(x: nil)
        Context.default.execute("Cosh", [x])
      end

      def count_up_to(ref: nil, limit: nil)
        Context.default.execute("CountUpTo", [ref], limit: limit)
      end

      def create_summary_db_writer(writer: nil, db_uri: nil, experiment_name: nil, run_name: nil, user_name: nil)
        Context.default.execute("CreateSummaryDbWriter", [writer, db_uri, experiment_name, run_name, user_name])
      end

      def create_summary_file_writer(writer: nil, logdir: nil, max_queue: nil, flush_millis: nil, filename_suffix: nil)
        Context.default.execute("CreateSummaryFileWriter", [writer, logdir, max_queue, flush_millis, filename_suffix])
      end

      def crop_and_resize(image: nil, boxes: nil, box_ind: nil, crop_size: nil, method: nil, extrapolation_value: nil)
        Context.default.execute("CropAndResize", [image, boxes, box_ind, crop_size], method: method, extrapolation_value: extrapolation_value)
      end

      def crop_and_resize_grad_boxes(grads: nil, image: nil, boxes: nil, box_ind: nil, method: nil)
        Context.default.execute("CropAndResizeGradBoxes", [grads, image, boxes, box_ind], method: method)
      end

      def crop_and_resize_grad_image(grads: nil, boxes: nil, box_ind: nil, image_size: nil, method: nil)
        Context.default.execute("CropAndResizeGradImage", [grads, boxes, box_ind, image_size], method: method)
      end

      def cross(a: nil, b: nil)
        Context.default.execute("Cross", [a, b])
      end

      def cross_replica_sum(input: nil, group_assignment: nil)
        Context.default.execute("CrossReplicaSum", [input, group_assignment])
      end

      def cudnn_rnn(input: nil, input_h: nil, input_c: nil, params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, is_training: nil)
        Context.default.execute("CudnnRNN", [input, input_h, input_c, params], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, is_training: is_training)
      end

      def cudnn_rnn_backprop(input: nil, input_h: nil, input_c: nil, params: nil, output: nil, output_h: nil, output_c: nil, output_backprop: nil, output_h_backprop: nil, output_c_backprop: nil, reserve_space: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
        Context.default.execute("CudnnRNNBackprop", [input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
      end

      def cudnn_rnn_backprop_v2(input: nil, input_h: nil, input_c: nil, params: nil, output: nil, output_h: nil, output_c: nil, output_backprop: nil, output_h_backprop: nil, output_c_backprop: nil, reserve_space: nil, host_reserved: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
        Context.default.execute("CudnnRNNBackpropV2", [input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, host_reserved], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
      end

      def cudnn_rnn_backprop_v3(input: nil, input_h: nil, input_c: nil, params: nil, sequence_lengths: nil, output: nil, output_h: nil, output_c: nil, output_backprop: nil, output_h_backprop: nil, output_c_backprop: nil, reserve_space: nil, host_reserved: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, time_major: nil)
        Context.default.execute("CudnnRNNBackpropV3", [input, input_h, input_c, params, sequence_lengths, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, host_reserved], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, time_major: time_major)
      end

      def cudnn_rnn_canonical_to_params(num_layers: nil, num_units: nil, input_size: nil, weights: nil, biases: nil, num_params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
        Context.default.execute("CudnnRNNCanonicalToParams", [num_layers, num_units, input_size, weights, biases], num_params: num_params, rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
      end

      def cudnn_rnn_params_size(num_layers: nil, num_units: nil, input_size: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
        Context.default.execute("CudnnRNNParamsSize", [num_layers, num_units, input_size], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
      end

      def cudnn_rnn_params_to_canonical(num_layers: nil, num_units: nil, input_size: nil, params: nil, num_params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil)
        Context.default.execute("CudnnRNNParamsToCanonical", [num_layers, num_units, input_size, params], num_params: num_params, rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2)
      end

      def cudnn_rnnv2(input: nil, input_h: nil, input_c: nil, params: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, is_training: nil)
        Context.default.execute("CudnnRNNV2", [input, input_h, input_c, params], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, is_training: is_training)
      end

      def cudnn_rnnv3(input: nil, input_h: nil, input_c: nil, params: nil, sequence_lengths: nil, rnn_mode: nil, input_mode: nil, direction: nil, dropout: nil, seed: nil, seed2: nil, is_training: nil, time_major: nil)
        Context.default.execute("CudnnRNNV3", [input, input_h, input_c, params, sequence_lengths], rnn_mode: rnn_mode, input_mode: input_mode, direction: direction, dropout: dropout, seed: seed, seed2: seed2, is_training: is_training, time_major: time_major)
      end

      def cumprod(x: nil, axis: nil, exclusive: nil, reverse: nil)
        Context.default.execute("Cumprod", [x, axis], exclusive: exclusive, reverse: reverse)
      end

      def cumsum(x: nil, axis: nil, exclusive: nil, reverse: nil)
        Context.default.execute("Cumsum", [x, axis], exclusive: exclusive, reverse: reverse)
      end

      def data_format_dim_map(x: nil, src_format: nil, dst_format: nil)
        Context.default.execute("DataFormatDimMap", [x], src_format: src_format, dst_format: dst_format)
      end

      def data_format_vec_permute(x: nil, src_format: nil, dst_format: nil)
        Context.default.execute("DataFormatVecPermute", [x], src_format: src_format, dst_format: dst_format)
      end

      def dataset_to_graph(input_dataset: nil)
        Context.default.execute("DatasetToGraph", [input_dataset])
      end

      def dataset_to_single_element(dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("DatasetToSingleElement", [dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def debug_gradient_identity(input: nil)
        Context.default.execute("DebugGradientIdentity", [input])
      end

      def debug_gradient_ref_identity(input: nil)
        Context.default.execute("DebugGradientRefIdentity", [input])
      end

      def debug_identity(input: nil, device_name: nil, tensor_name: nil, debug_urls: nil, gated_grpc: nil)
        Context.default.execute("DebugIdentity", [input], device_name: device_name, tensor_name: tensor_name, debug_urls: debug_urls, gated_grpc: gated_grpc)
      end

      def debug_nan_count(input: nil, device_name: nil, tensor_name: nil, debug_urls: nil, gated_grpc: nil)
        Context.default.execute("DebugNanCount", [input], device_name: device_name, tensor_name: tensor_name, debug_urls: debug_urls, gated_grpc: gated_grpc)
      end

      def debug_numeric_summary(input: nil, device_name: nil, tensor_name: nil, debug_urls: nil, lower_bound: nil, upper_bound: nil, mute_if_healthy: nil, gated_grpc: nil)
        Context.default.execute("DebugNumericSummary", [input], device_name: device_name, tensor_name: tensor_name, debug_urls: debug_urls, lower_bound: lower_bound, upper_bound: upper_bound, mute_if_healthy: mute_if_healthy, gated_grpc: gated_grpc)
      end

      def decode_and_crop_jpeg(contents: nil, crop_window: nil, channels: nil, ratio: nil, fancy_upscaling: nil, try_recover_truncated: nil, acceptable_fraction: nil, dct_method: nil)
        Context.default.execute("DecodeAndCropJpeg", [contents, crop_window], channels: channels, ratio: ratio, fancy_upscaling: fancy_upscaling, try_recover_truncated: try_recover_truncated, acceptable_fraction: acceptable_fraction, dct_method: dct_method)
      end

      def decode_base64(input: nil)
        Context.default.execute("DecodeBase64", [input])
      end

      def decode_bmp(contents: nil, channels: nil)
        Context.default.execute("DecodeBmp", [contents], channels: channels)
      end

      def decode_csv(records: nil, record_defaults: nil, field_delim: nil, use_quote_delim: nil, na_value: nil, select_cols: nil)
        Context.default.execute("DecodeCSV", [records, record_defaults], field_delim: field_delim, use_quote_delim: use_quote_delim, na_value: na_value, select_cols: select_cols)
      end

      def decode_compressed(bytes: nil, compression_type: nil)
        Context.default.execute("DecodeCompressed", [bytes], compression_type: compression_type)
      end

      def decode_gif(contents: nil)
        Context.default.execute("DecodeGif", [contents])
      end

      def decode_json_example(json_examples: nil)
        Context.default.execute("DecodeJSONExample", [json_examples])
      end

      def decode_jpeg(contents: nil, channels: nil, ratio: nil, fancy_upscaling: nil, try_recover_truncated: nil, acceptable_fraction: nil, dct_method: nil)
        Context.default.execute("DecodeJpeg", [contents], channels: channels, ratio: ratio, fancy_upscaling: fancy_upscaling, try_recover_truncated: try_recover_truncated, acceptable_fraction: acceptable_fraction, dct_method: dct_method)
      end

      def decode_padded_raw(input_bytes: nil, fixed_length: nil, out_type: nil, little_endian: nil)
        Context.default.execute("DecodePaddedRaw", [input_bytes, fixed_length], out_type: out_type, little_endian: little_endian)
      end

      def decode_png(contents: nil, channels: nil, dtype: nil)
        Context.default.execute("DecodePng", [contents], channels: channels, dtype: dtype)
      end

      def decode_proto_v2(bytes: nil, message_type: nil, field_names: nil, output_types: nil, descriptor_source: nil, message_format: nil, sanitize: nil)
        Context.default.execute("DecodeProtoV2", [bytes], message_type: message_type, field_names: field_names, output_types: output_types, descriptor_source: descriptor_source, message_format: message_format, sanitize: sanitize)
      end

      def decode_raw(bytes: nil, out_type: nil, little_endian: nil)
        Context.default.execute("DecodeRaw", [bytes], out_type: out_type, little_endian: little_endian)
      end

      def decode_wav(contents: nil, desired_channels: nil, desired_samples: nil)
        Context.default.execute("DecodeWav", [contents], desired_channels: desired_channels, desired_samples: desired_samples)
      end

      def deep_copy(x: nil)
        Context.default.execute("DeepCopy", [x])
      end

      def delete_iterator(handle: nil, deleter: nil)
        Context.default.execute("DeleteIterator", [handle, deleter])
      end

      def delete_session_tensor(handle: nil)
        Context.default.execute("DeleteSessionTensor", [handle])
      end

      def dense_to_dense_set_operation(set1: nil, set2: nil, set_operation: nil, validate_indices: nil)
        Context.default.execute("DenseToDenseSetOperation", [set1, set2], set_operation: set_operation, validate_indices: validate_indices)
      end

      def dense_to_sparse_set_operation(set1: nil, set2_indices: nil, set2_values: nil, set2_shape: nil, set_operation: nil, validate_indices: nil)
        Context.default.execute("DenseToSparseSetOperation", [set1, set2_indices, set2_values, set2_shape], set_operation: set_operation, validate_indices: validate_indices)
      end

      def depth_to_space(input: nil, block_size: nil, data_format: nil)
        Context.default.execute("DepthToSpace", [input], block_size: block_size, data_format: data_format)
      end

      def depthwise_conv2d_native(input: nil, filter: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
        Context.default.execute("DepthwiseConv2dNative", [input, filter], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
      end

      def depthwise_conv2d_native_backprop_filter(input: nil, filter_sizes: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
        Context.default.execute("DepthwiseConv2dNativeBackpropFilter", [input, filter_sizes, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
      end

      def depthwise_conv2d_native_backprop_input(input_sizes: nil, filter: nil, out_backprop: nil, strides: nil, padding: nil, data_format: nil, dilations: nil)
        Context.default.execute("DepthwiseConv2dNativeBackpropInput", [input_sizes, filter, out_backprop], strides: strides, padding: padding, data_format: data_format, dilations: dilations)
      end

      def dequantize(input: nil, min_range: nil, max_range: nil, mode: nil)
        Context.default.execute("Dequantize", [input, min_range, max_range], mode: mode)
      end

      def deserialize_iterator(resource_handle: nil, serialized: nil)
        Context.default.execute("DeserializeIterator", [resource_handle, serialized])
      end

      def deserialize_many_sparse(serialized_sparse: nil, dtype: nil)
        Context.default.execute("DeserializeManySparse", [serialized_sparse], dtype: dtype)
      end

      def deserialize_sparse(serialized_sparse: nil, dtype: nil)
        Context.default.execute("DeserializeSparse", [serialized_sparse], dtype: dtype)
      end

      def destroy_resource_op(resource: nil, ignore_lookup_error: nil)
        Context.default.execute("DestroyResourceOp", [resource], ignore_lookup_error: ignore_lookup_error)
      end

      def destroy_temporary_variable(ref: nil, var_name: nil)
        Context.default.execute("DestroyTemporaryVariable", [ref], var_name: var_name)
      end

      def diag(diagonal: nil)
        Context.default.execute("Diag", [diagonal])
      end

      def diag_part(input: nil)
        Context.default.execute("DiagPart", [input])
      end

      def digamma(x: nil)
        Context.default.execute("Digamma", [x])
      end

      def dilation2d(input: nil, filter: nil, strides: nil, rates: nil, padding: nil)
        Context.default.execute("Dilation2D", [input, filter], strides: strides, rates: rates, padding: padding)
      end

      def dilation2d_backprop_filter(input: nil, filter: nil, out_backprop: nil, strides: nil, rates: nil, padding: nil)
        Context.default.execute("Dilation2DBackpropFilter", [input, filter, out_backprop], strides: strides, rates: rates, padding: padding)
      end

      def dilation2d_backprop_input(input: nil, filter: nil, out_backprop: nil, strides: nil, rates: nil, padding: nil)
        Context.default.execute("Dilation2DBackpropInput", [input, filter, out_backprop], strides: strides, rates: rates, padding: padding)
      end

      def div(x: nil, y: nil)
        Context.default.execute("Div", [x, y])
      end

      def div_no_nan(x: nil, y: nil)
        Context.default.execute("DivNoNan", [x, y])
      end

      def draw_bounding_boxes(images: nil, boxes: nil)
        Context.default.execute("DrawBoundingBoxes", [images, boxes])
      end

      def draw_bounding_boxes_v2(images: nil, boxes: nil, colors: nil)
        Context.default.execute("DrawBoundingBoxesV2", [images, boxes, colors])
      end

      def dynamic_partition(data: nil, partitions: nil, num_partitions: nil)
        Context.default.execute("DynamicPartition", [data, partitions], num_partitions: num_partitions)
      end

      def dynamic_stitch(indices: nil, data: nil)
        Context.default.execute("DynamicStitch", [indices, data])
      end

      def eager_py_func(input: nil, token: nil)
        Context.default.execute("EagerPyFunc", [input], token: token)
      end

      def edit_distance(hypothesis_indices: nil, hypothesis_values: nil, hypothesis_shape: nil, truth_indices: nil, truth_values: nil, truth_shape: nil, normalize: nil)
        Context.default.execute("EditDistance", [hypothesis_indices, hypothesis_values, hypothesis_shape, truth_indices, truth_values, truth_shape], normalize: normalize)
      end

      def elu(features: nil)
        Context.default.execute("Elu", [features])
      end

      def elu_grad(gradients: nil, outputs: nil)
        Context.default.execute("EluGrad", [gradients, outputs])
      end

      def empty(shape: nil, dtype: nil, init: nil)
        Context.default.execute("Empty", [shape], dtype: dtype, init: init)
      end

      def empty_tensor_list(element_shape: nil, max_num_elements: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("EmptyTensorList", [element_shape, max_num_elements], element_dtype: element_dtype, shape_type: shape_type)
      end

      def encode_base64(input: nil, pad: nil)
        Context.default.execute("EncodeBase64", [input], pad: pad)
      end

      def encode_jpeg(image: nil, format: nil, quality: nil, progressive: nil, optimize_size: nil, chroma_downsampling: nil, density_unit: nil, x_density: nil, y_density: nil, xmp_metadata: nil)
        Context.default.execute("EncodeJpeg", [image], format: format, quality: quality, progressive: progressive, optimize_size: optimize_size, chroma_downsampling: chroma_downsampling, density_unit: density_unit, x_density: x_density, y_density: y_density, xmp_metadata: xmp_metadata)
      end

      def encode_jpeg_variable_quality(images: nil, quality: nil)
        Context.default.execute("EncodeJpegVariableQuality", [images, quality])
      end

      def encode_png(image: nil, compression: nil)
        Context.default.execute("EncodePng", [image], compression: compression)
      end

      def encode_proto(sizes: nil, values: nil, field_names: nil, message_type: nil, descriptor_source: nil)
        Context.default.execute("EncodeProto", [sizes, values], field_names: field_names, message_type: message_type, descriptor_source: descriptor_source)
      end

      def encode_wav(audio: nil, sample_rate: nil)
        Context.default.execute("EncodeWav", [audio, sample_rate])
      end

      def enqueue_tpu_embedding_integer_batch(batch: nil, mode_override: nil, device_ordinal: nil)
        Context.default.execute("EnqueueTPUEmbeddingIntegerBatch", [batch, mode_override], device_ordinal: device_ordinal)
      end

      def enqueue_tpu_embedding_sparse_batch(sample_indices: nil, embedding_indices: nil, aggregation_weights: nil, mode_override: nil, device_ordinal: nil, combiners: nil)
        Context.default.execute("EnqueueTPUEmbeddingSparseBatch", [sample_indices, embedding_indices, aggregation_weights, mode_override], device_ordinal: device_ordinal, combiners: combiners)
      end

      def enqueue_tpu_embedding_sparse_tensor_batch(sample_indices: nil, embedding_indices: nil, aggregation_weights: nil, mode_override: nil, device_ordinal: nil, combiners: nil, table_ids: nil, max_sequence_lengths: nil)
        Context.default.execute("EnqueueTPUEmbeddingSparseTensorBatch", [sample_indices, embedding_indices, aggregation_weights, mode_override], device_ordinal: device_ordinal, combiners: combiners, table_ids: table_ids, max_sequence_lengths: max_sequence_lengths)
      end

      def ensure_shape(input: nil, shape: nil)
        Context.default.execute("EnsureShape", [input], shape: shape)
      end

      def enter(data: nil, frame_name: nil, is_constant: nil, parallel_iterations: nil)
        Context.default.execute("Enter", [data], frame_name: frame_name, is_constant: is_constant, parallel_iterations: parallel_iterations)
      end

      def equal(x: nil, y: nil)
        Context.default.execute("Equal", [x, y])
      end

      def erf(x: nil)
        Context.default.execute("Erf", [x])
      end

      def erfc(x: nil)
        Context.default.execute("Erfc", [x])
      end

      def euclidean_norm(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("EuclideanNorm", [input, reduction_indices], keep_dims: keep_dims)
      end

      def exit(data: nil)
        Context.default.execute("Exit", [data])
      end

      def exp(x: nil)
        Context.default.execute("Exp", [x])
      end

      def expand_dims(input: nil, dim: nil)
        Context.default.execute("ExpandDims", [input, dim])
      end

      def experimental_assert_next_dataset(input_dataset: nil, transformations: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalAssertNextDataset", [input_dataset, transformations], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_auto_shard_dataset(input_dataset: nil, num_workers: nil, index: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalAutoShardDataset", [input_dataset, num_workers, index], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_bytes_produced_stats_dataset(input_dataset: nil, tag: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalBytesProducedStatsDataset", [input_dataset, tag], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_csv_dataset(filenames: nil, compression_type: nil, buffer_size: nil, header: nil, field_delim: nil, use_quote_delim: nil, na_value: nil, select_cols: nil, record_defaults: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalCSVDataset", [filenames, compression_type, buffer_size, header, field_delim, use_quote_delim, na_value, select_cols, record_defaults], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_choose_fastest_dataset(input_datasets: nil, num_experiments: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalChooseFastestDataset", [input_datasets], num_experiments: num_experiments, output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_dataset_cardinality(input_dataset: nil)
        Context.default.execute("ExperimentalDatasetCardinality", [input_dataset])
      end

      def experimental_dataset_to_tf_record(input_dataset: nil, filename: nil, compression_type: nil)
        Context.default.execute("ExperimentalDatasetToTFRecord", [input_dataset, filename, compression_type])
      end

      def experimental_dense_to_sparse_batch_dataset(input_dataset: nil, batch_size: nil, row_shape: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalDenseToSparseBatchDataset", [input_dataset, batch_size, row_shape], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_directed_interleave_dataset(selector_input_dataset: nil, data_input_datasets: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalDirectedInterleaveDataset", [selector_input_dataset, data_input_datasets], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_group_by_reducer_dataset(input_dataset: nil, key_func_other_arguments: nil, init_func_other_arguments: nil, reduce_func_other_arguments: nil, finalize_func_other_arguments: nil, key_func: nil, init_func: nil, reduce_func: nil, finalize_func: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalGroupByReducerDataset", [input_dataset, key_func_other_arguments, init_func_other_arguments, reduce_func_other_arguments, finalize_func_other_arguments], key_func: key_func, init_func: init_func, reduce_func: reduce_func, finalize_func: finalize_func, output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_group_by_window_dataset(input_dataset: nil, key_func_other_arguments: nil, reduce_func_other_arguments: nil, window_size_func_other_arguments: nil, key_func: nil, reduce_func: nil, window_size_func: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalGroupByWindowDataset", [input_dataset, key_func_other_arguments, reduce_func_other_arguments, window_size_func_other_arguments], key_func: key_func, reduce_func: reduce_func, window_size_func: window_size_func, output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_identity_indexed_dataset(size: nil)
        Context.default.execute("ExperimentalIdentityIndexedDataset", [size])
      end

      def experimental_ignore_errors_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalIgnoreErrorsDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_indexed_dataset_get(materialized: nil, index: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalIndexedDatasetGet", [materialized, index], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_indexed_dataset_materialize(dataset: nil, materialized: nil)
        Context.default.execute("ExperimentalIndexedDatasetMaterialize", [dataset, materialized])
      end

      def experimental_iterator_get_device(resource: nil)
        Context.default.execute("ExperimentalIteratorGetDevice", [resource])
      end

      def experimental_lmdb_dataset(filenames: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalLMDBDataset", [filenames], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_latency_stats_dataset(input_dataset: nil, tag: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalLatencyStatsDataset", [input_dataset, tag], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_map_and_batch_dataset(input_dataset: nil, other_arguments: nil, batch_size: nil, num_parallel_calls: nil, drop_remainder: nil, f: nil, output_types: nil, output_shapes: nil, preserve_cardinality: nil)
        Context.default.execute("ExperimentalMapAndBatchDataset", [input_dataset, other_arguments, batch_size, num_parallel_calls, drop_remainder], f: f, output_types: output_types, output_shapes: output_shapes, preserve_cardinality: preserve_cardinality)
      end

      def experimental_map_dataset(input_dataset: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil, preserve_cardinality: nil)
        Context.default.execute("ExperimentalMapDataset", [input_dataset, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism, preserve_cardinality: preserve_cardinality)
      end

      def experimental_matching_files_dataset(patterns: nil)
        Context.default.execute("ExperimentalMatchingFilesDataset", [patterns])
      end

      def experimental_materialized_index_dataset_handle(container: nil, shared_name: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalMaterializedIndexDatasetHandle", [], container: container, shared_name: shared_name, output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_max_intra_op_parallelism_dataset(input_dataset: nil, max_intra_op_parallelism: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalMaxIntraOpParallelismDataset", [input_dataset, max_intra_op_parallelism], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_non_serializable_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalNonSerializableDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_numa_map_and_batch_dataset(input_dataset: nil, other_arguments: nil, batch_size: nil, num_parallel_calls: nil, drop_remainder: nil, f: nil, output_types: nil, output_shapes: nil, preserve_cardinality: nil)
        Context.default.execute("ExperimentalNumaMapAndBatchDataset", [input_dataset, other_arguments, batch_size, num_parallel_calls, drop_remainder], f: f, output_types: output_types, output_shapes: output_shapes, preserve_cardinality: preserve_cardinality)
      end

      def experimental_parallel_interleave_dataset(input_dataset: nil, other_arguments: nil, cycle_length: nil, block_length: nil, sloppy: nil, buffer_output_elements: nil, prefetch_input_elements: nil, f: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalParallelInterleaveDataset", [input_dataset, other_arguments, cycle_length, block_length, sloppy, buffer_output_elements, prefetch_input_elements], f: f, output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_parse_example_dataset(input_dataset: nil, num_parallel_calls: nil, dense_defaults: nil, sparse_keys: nil, dense_keys: nil, sparse_types: nil, dense_shapes: nil, output_types: nil, output_shapes: nil, sloppy: nil)
        Context.default.execute("ExperimentalParseExampleDataset", [input_dataset, num_parallel_calls, dense_defaults], sparse_keys: sparse_keys, dense_keys: dense_keys, sparse_types: sparse_types, dense_shapes: dense_shapes, output_types: output_types, output_shapes: output_shapes, sloppy: sloppy)
      end

      def experimental_private_thread_pool_dataset(input_dataset: nil, num_threads: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalPrivateThreadPoolDataset", [input_dataset, num_threads], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_random_dataset(seed: nil, seed2: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalRandomDataset", [seed, seed2], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_rebatch_dataset(input_dataset: nil, num_workers: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalRebatchDataset", [input_dataset, num_workers], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_scan_dataset(input_dataset: nil, initial_state: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, preserve_cardinality: nil)
        Context.default.execute("ExperimentalScanDataset", [input_dataset, initial_state, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, preserve_cardinality: preserve_cardinality)
      end

      def experimental_set_stats_aggregator_dataset(input_dataset: nil, stats_aggregator: nil, tag: nil, counter_prefix: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalSetStatsAggregatorDataset", [input_dataset, stats_aggregator, tag, counter_prefix], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_sleep_dataset(input_dataset: nil, sleep_microseconds: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalSleepDataset", [input_dataset, sleep_microseconds], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_sliding_window_dataset(input_dataset: nil, window_size: nil, window_shift: nil, window_stride: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalSlidingWindowDataset", [input_dataset, window_size, window_shift, window_stride], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_sql_dataset(driver_name: nil, data_source_name: nil, query: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalSqlDataset", [driver_name, data_source_name, query], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_stats_aggregator_handle(container: nil, shared_name: nil)
        Context.default.execute("ExperimentalStatsAggregatorHandle", [], container: container, shared_name: shared_name)
      end

      def experimental_stats_aggregator_summary(iterator: nil)
        Context.default.execute("ExperimentalStatsAggregatorSummary", [iterator])
      end

      def experimental_take_while_dataset(input_dataset: nil, other_arguments: nil, predicate: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalTakeWhileDataset", [input_dataset, other_arguments], predicate: predicate, output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_thread_pool_dataset(input_dataset: nil, thread_pool: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalThreadPoolDataset", [input_dataset, thread_pool], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_thread_pool_handle(num_threads: nil, max_intra_op_parallelism: nil, display_name: nil, container: nil, shared_name: nil)
        Context.default.execute("ExperimentalThreadPoolHandle", [], num_threads: num_threads, max_intra_op_parallelism: max_intra_op_parallelism, display_name: display_name, container: container, shared_name: shared_name)
      end

      def experimental_unbatch_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalUnbatchDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def experimental_unique_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ExperimentalUniqueDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def expm1(x: nil)
        Context.default.execute("Expm1", [x])
      end

      def extract_glimpse(input: nil, size: nil, offsets: nil, centered: nil, normalized: nil, uniform_noise: nil, noise: nil)
        Context.default.execute("ExtractGlimpse", [input, size, offsets], centered: centered, normalized: normalized, uniform_noise: uniform_noise, noise: noise)
      end

      def extract_image_patches(images: nil, ksizes: nil, strides: nil, rates: nil, padding: nil)
        Context.default.execute("ExtractImagePatches", [images], ksizes: ksizes, strides: strides, rates: rates, padding: padding)
      end

      def extract_jpeg_shape(contents: nil, output_type: nil)
        Context.default.execute("ExtractJpegShape", [contents], output_type: output_type)
      end

      def extract_volume_patches(input: nil, ksizes: nil, strides: nil, padding: nil)
        Context.default.execute("ExtractVolumePatches", [input], ksizes: ksizes, strides: strides, padding: padding)
      end

      def fft(input: nil)
        Context.default.execute("FFT", [input])
      end

      def fft2d(input: nil)
        Context.default.execute("FFT2D", [input])
      end

      def fft3d(input: nil)
        Context.default.execute("FFT3D", [input])
      end

      def fifo_queue(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("FIFOQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def fifo_queue_v2(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("FIFOQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def fact
        Context.default.execute("Fact", [])
      end

      def fake_param(dtype: nil, shape: nil)
        Context.default.execute("FakeParam", [], dtype: dtype, shape: shape)
      end

      def fake_quant_with_min_max_args(inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
        Context.default.execute("FakeQuantWithMinMaxArgs", [inputs], min: min, max: max, num_bits: num_bits, narrow_range: narrow_range)
      end

      def fake_quant_with_min_max_args_gradient(gradients: nil, inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
        Context.default.execute("FakeQuantWithMinMaxArgsGradient", [gradients, inputs], min: min, max: max, num_bits: num_bits, narrow_range: narrow_range)
      end

      def fake_quant_with_min_max_vars(inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
        Context.default.execute("FakeQuantWithMinMaxVars", [inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
      end

      def fake_quant_with_min_max_vars_gradient(gradients: nil, inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
        Context.default.execute("FakeQuantWithMinMaxVarsGradient", [gradients, inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
      end

      def fake_quant_with_min_max_vars_per_channel(inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
        Context.default.execute("FakeQuantWithMinMaxVarsPerChannel", [inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
      end

      def fake_quant_with_min_max_vars_per_channel_gradient(gradients: nil, inputs: nil, min: nil, max: nil, num_bits: nil, narrow_range: nil)
        Context.default.execute("FakeQuantWithMinMaxVarsPerChannelGradient", [gradients, inputs, min, max], num_bits: num_bits, narrow_range: narrow_range)
      end

      def fake_queue(resource: nil)
        Context.default.execute("FakeQueue", [resource])
      end

      def fill(dims: nil, value: nil, index_type: nil)
        Context.default.execute("Fill", [dims, value], index_type: index_type)
      end

      def filter_by_last_component_dataset(input_dataset: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("FilterByLastComponentDataset", [input_dataset], output_types: output_types, output_shapes: output_shapes)
      end

      def filter_dataset(input_dataset: nil, other_arguments: nil, predicate: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("FilterDataset", [input_dataset, other_arguments], predicate: predicate, output_types: output_types, output_shapes: output_shapes)
      end

      def fingerprint(data: nil, method: nil)
        Context.default.execute("Fingerprint", [data, method])
      end

      def fixed_length_record_dataset(filenames: nil, header_bytes: nil, record_bytes: nil, footer_bytes: nil, buffer_size: nil)
        Context.default.execute("FixedLengthRecordDataset", [filenames, header_bytes, record_bytes, footer_bytes, buffer_size])
      end

      def fixed_length_record_dataset_v2(filenames: nil, header_bytes: nil, record_bytes: nil, footer_bytes: nil, buffer_size: nil, compression_type: nil)
        Context.default.execute("FixedLengthRecordDatasetV2", [filenames, header_bytes, record_bytes, footer_bytes, buffer_size, compression_type])
      end

      def fixed_length_record_reader(header_bytes: nil, record_bytes: nil, footer_bytes: nil, hop_bytes: nil, container: nil, shared_name: nil)
        Context.default.execute("FixedLengthRecordReader", [], header_bytes: header_bytes, record_bytes: record_bytes, footer_bytes: footer_bytes, hop_bytes: hop_bytes, container: container, shared_name: shared_name)
      end

      def fixed_length_record_reader_v2(header_bytes: nil, record_bytes: nil, footer_bytes: nil, hop_bytes: nil, container: nil, shared_name: nil, encoding: nil)
        Context.default.execute("FixedLengthRecordReaderV2", [], header_bytes: header_bytes, record_bytes: record_bytes, footer_bytes: footer_bytes, hop_bytes: hop_bytes, container: container, shared_name: shared_name, encoding: encoding)
      end

      def fixed_unigram_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, vocab_file: nil, distortion: nil, num_reserved_ids: nil, num_shards: nil, shard: nil, unigrams: nil, seed: nil, seed2: nil)
        Context.default.execute("FixedUnigramCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, vocab_file: vocab_file, distortion: distortion, num_reserved_ids: num_reserved_ids, num_shards: num_shards, shard: shard, unigrams: unigrams, seed: seed, seed2: seed2)
      end

      def flat_map_dataset(input_dataset: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("FlatMapDataset", [input_dataset, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes)
      end

      def floor(x: nil)
        Context.default.execute("Floor", [x])
      end

      def floor_div(x: nil, y: nil)
        Context.default.execute("FloorDiv", [x, y])
      end

      def floor_mod(x: nil, y: nil)
        Context.default.execute("FloorMod", [x, y])
      end

      def flush_summary_writer(writer: nil)
        Context.default.execute("FlushSummaryWriter", [writer])
      end

      def for(start: nil, limit: nil, delta: nil, input: nil, body: nil)
        Context.default.execute("For", [start, limit, delta, input], body: body)
      end

      def fractional_avg_pool(value: nil, pooling_ratio: nil, pseudo_random: nil, overlapping: nil, deterministic: nil, seed: nil, seed2: nil)
        Context.default.execute("FractionalAvgPool", [value], pooling_ratio: pooling_ratio, pseudo_random: pseudo_random, overlapping: overlapping, deterministic: deterministic, seed: seed, seed2: seed2)
      end

      def fractional_avg_pool_grad(orig_input_tensor_shape: nil, out_backprop: nil, row_pooling_sequence: nil, col_pooling_sequence: nil, overlapping: nil)
        Context.default.execute("FractionalAvgPoolGrad", [orig_input_tensor_shape, out_backprop, row_pooling_sequence, col_pooling_sequence], overlapping: overlapping)
      end

      def fractional_max_pool(value: nil, pooling_ratio: nil, pseudo_random: nil, overlapping: nil, deterministic: nil, seed: nil, seed2: nil)
        Context.default.execute("FractionalMaxPool", [value], pooling_ratio: pooling_ratio, pseudo_random: pseudo_random, overlapping: overlapping, deterministic: deterministic, seed: seed, seed2: seed2)
      end

      def fractional_max_pool_grad(orig_input: nil, orig_output: nil, out_backprop: nil, row_pooling_sequence: nil, col_pooling_sequence: nil, overlapping: nil)
        Context.default.execute("FractionalMaxPoolGrad", [orig_input, orig_output, out_backprop, row_pooling_sequence, col_pooling_sequence], overlapping: overlapping)
      end

      def fused_batch_norm(x: nil, scale: nil, offset: nil, mean: nil, variance: nil, epsilon: nil, data_format: nil, is_training: nil)
        Context.default.execute("FusedBatchNorm", [x, scale, offset, mean, variance], epsilon: epsilon, data_format: data_format, is_training: is_training)
      end

      def fused_batch_norm_grad(y_backprop: nil, x: nil, scale: nil, reserve_space_1: nil, reserve_space_2: nil, epsilon: nil, data_format: nil, is_training: nil)
        Context.default.execute("FusedBatchNormGrad", [y_backprop, x, scale, reserve_space_1, reserve_space_2], epsilon: epsilon, data_format: data_format, is_training: is_training)
      end

      def fused_batch_norm_grad_v2(y_backprop: nil, x: nil, scale: nil, reserve_space_1: nil, reserve_space_2: nil, epsilon: nil, data_format: nil, is_training: nil)
        Context.default.execute("FusedBatchNormGradV2", [y_backprop, x, scale, reserve_space_1, reserve_space_2], epsilon: epsilon, data_format: data_format, is_training: is_training)
      end

      def fused_batch_norm_grad_v3(y_backprop: nil, x: nil, scale: nil, reserve_space_1: nil, reserve_space_2: nil, reserve_space_3: nil, epsilon: nil, data_format: nil, is_training: nil)
        Context.default.execute("FusedBatchNormGradV3", [y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3], epsilon: epsilon, data_format: data_format, is_training: is_training)
      end

      def fused_batch_norm_v2(x: nil, scale: nil, offset: nil, mean: nil, variance: nil, epsilon: nil, data_format: nil, is_training: nil)
        Context.default.execute("FusedBatchNormV2", [x, scale, offset, mean, variance], epsilon: epsilon, data_format: data_format, is_training: is_training)
      end

      def fused_batch_norm_v3(x: nil, scale: nil, offset: nil, mean: nil, variance: nil, epsilon: nil, data_format: nil, is_training: nil)
        Context.default.execute("FusedBatchNormV3", [x, scale, offset, mean, variance], epsilon: epsilon, data_format: data_format, is_training: is_training)
      end

      def fused_pad_conv2d(input: nil, paddings: nil, filter: nil, mode: nil, strides: nil, padding: nil)
        Context.default.execute("FusedPadConv2D", [input, paddings, filter], mode: mode, strides: strides, padding: padding)
      end

      def fused_resize_and_pad_conv2d(input: nil, size: nil, paddings: nil, filter: nil, resize_align_corners: nil, mode: nil, strides: nil, padding: nil)
        Context.default.execute("FusedResizeAndPadConv2D", [input, size, paddings, filter], resize_align_corners: resize_align_corners, mode: mode, strides: strides, padding: padding)
      end

      def gather(params: nil, indices: nil, validate_indices: nil)
        Context.default.execute("Gather", [params, indices], validate_indices: validate_indices)
      end

      def gather_nd(params: nil, indices: nil)
        Context.default.execute("GatherNd", [params, indices])
      end

      def gather_v2(params: nil, indices: nil, axis: nil, batch_dims: nil)
        Context.default.execute("GatherV2", [params, indices, axis], batch_dims: batch_dims)
      end

      def gcs_configure_block_cache(max_cache_size: nil, block_size: nil, max_staleness: nil)
        Context.default.execute("GcsConfigureBlockCache", [max_cache_size, block_size, max_staleness])
      end

      def gcs_configure_credentials(json: nil)
        Context.default.execute("GcsConfigureCredentials", [json])
      end

      def generate_big_query_reader_partitions(project_id: nil, dataset_id: nil, table_id: nil, columns: nil, timestamp_millis: nil, num_partitions: nil, test_end_point: nil)
        Context.default.execute("GenerateBigQueryReaderPartitions", [], project_id: project_id, dataset_id: dataset_id, table_id: table_id, columns: columns, timestamp_millis: timestamp_millis, num_partitions: num_partitions, test_end_point: test_end_point)
      end

      def generate_vocab_remapping(new_vocab_file: nil, old_vocab_file: nil, new_vocab_offset: nil, num_new_vocab: nil, old_vocab_size: nil)
        Context.default.execute("GenerateVocabRemapping", [new_vocab_file, old_vocab_file], new_vocab_offset: new_vocab_offset, num_new_vocab: num_new_vocab, old_vocab_size: old_vocab_size)
      end

      def generator_dataset(init_func_other_args: nil, next_func_other_args: nil, finalize_func_other_args: nil, init_func: nil, next_func: nil, finalize_func: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("GeneratorDataset", [init_func_other_args, next_func_other_args, finalize_func_other_args], init_func: init_func, next_func: next_func, finalize_func: finalize_func, output_types: output_types, output_shapes: output_shapes)
      end

      def get_session_handle(value: nil)
        Context.default.execute("GetSessionHandle", [value])
      end

      def get_session_handle_v2(value: nil)
        Context.default.execute("GetSessionHandleV2", [value])
      end

      def get_session_tensor(handle: nil, dtype: nil)
        Context.default.execute("GetSessionTensor", [handle], dtype: dtype)
      end

      def greater(x: nil, y: nil)
        Context.default.execute("Greater", [x, y])
      end

      def greater_equal(x: nil, y: nil)
        Context.default.execute("GreaterEqual", [x, y])
      end

      def guarantee_const(input: nil)
        Context.default.execute("GuaranteeConst", [input])
      end

      def hsv_to_rgb(images: nil)
        Context.default.execute("HSVToRGB", [images])
      end

      def hash_table(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
        Context.default.execute("HashTable", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
      end

      def hash_table_v2(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
        Context.default.execute("HashTableV2", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
      end

      def histogram_fixed_width(values: nil, value_range: nil, nbins: nil, dtype: nil)
        Context.default.execute("HistogramFixedWidth", [values, value_range, nbins], dtype: dtype)
      end

      def histogram_summary(tag: nil, values: nil)
        Context.default.execute("HistogramSummary", [tag, values])
      end

      def host_const(value: nil, dtype: nil)
        Context.default.execute("HostConst", [], value: value, dtype: dtype)
      end

      def ifft(input: nil)
        Context.default.execute("IFFT", [input])
      end

      def ifft2d(input: nil)
        Context.default.execute("IFFT2D", [input])
      end

      def ifft3d(input: nil)
        Context.default.execute("IFFT3D", [input])
      end

      def irfft(input: nil, fft_length: nil)
        Context.default.execute("IRFFT", [input, fft_length])
      end

      def irfft2d(input: nil, fft_length: nil)
        Context.default.execute("IRFFT2D", [input, fft_length])
      end

      def irfft3d(input: nil, fft_length: nil)
        Context.default.execute("IRFFT3D", [input, fft_length])
      end

      def identity(input: nil)
        Context.default.execute("Identity", [input])
      end

      def identity_n(input: nil)
        Context.default.execute("IdentityN", [input])
      end

      def identity_reader(container: nil, shared_name: nil)
        Context.default.execute("IdentityReader", [], container: container, shared_name: shared_name)
      end

      def identity_reader_v2(container: nil, shared_name: nil)
        Context.default.execute("IdentityReaderV2", [], container: container, shared_name: shared_name)
      end

      def if(cond: nil, input: nil, then_branch: nil, else_branch: nil, output_shapes: nil)
        Context.default.execute("If", [cond, input], then_branch: then_branch, else_branch: else_branch, output_shapes: output_shapes)
      end

      def igamma(a: nil, x: nil)
        Context.default.execute("Igamma", [a, x])
      end

      def igamma_grad_a(a: nil, x: nil)
        Context.default.execute("IgammaGradA", [a, x])
      end

      def igammac(a: nil, x: nil)
        Context.default.execute("Igammac", [a, x])
      end

      def imag(input: nil)
        Context.default.execute("Imag", [input])
      end

      def image_summary(tag: nil, tensor: nil, max_images: nil, bad_color: nil)
        Context.default.execute("ImageSummary", [tag, tensor], max_images: max_images, bad_color: bad_color)
      end

      def immutable_const(dtype: nil, shape: nil, memory_region_name: nil)
        Context.default.execute("ImmutableConst", [], dtype: dtype, shape: shape, memory_region_name: memory_region_name)
      end

      def import_event(writer: nil, event: nil)
        Context.default.execute("ImportEvent", [writer, event])
      end

      def in_top_k(predictions: nil, targets: nil, k: nil)
        Context.default.execute("InTopK", [predictions, targets], k: k)
      end

      def in_top_kv2(predictions: nil, targets: nil, k: nil)
        Context.default.execute("InTopKV2", [predictions, targets, k])
      end

      def infeed_dequeue(dtype: nil, shape: nil)
        Context.default.execute("InfeedDequeue", [], dtype: dtype, shape: shape)
      end

      def infeed_dequeue_tuple(dtypes: nil, shapes: nil)
        Context.default.execute("InfeedDequeueTuple", [], dtypes: dtypes, shapes: shapes)
      end

      def infeed_enqueue(input: nil, dtype: nil, shape: nil, layout: nil, device_ordinal: nil)
        Context.default.execute("InfeedEnqueue", [input], dtype: dtype, shape: shape, layout: layout, device_ordinal: device_ordinal)
      end

      def infeed_enqueue_prelinearized_buffer(input: nil, device_ordinal: nil)
        Context.default.execute("InfeedEnqueuePrelinearizedBuffer", [input], device_ordinal: device_ordinal)
      end

      def infeed_enqueue_tuple(inputs: nil, dtypes: nil, shapes: nil, layouts: nil, device_ordinal: nil)
        Context.default.execute("InfeedEnqueueTuple", [inputs], dtypes: dtypes, shapes: shapes, layouts: layouts, device_ordinal: device_ordinal)
      end

      def initialize_table(table_handle: nil, keys: nil, values: nil)
        Context.default.execute("InitializeTable", [table_handle, keys, values])
      end

      def initialize_table_from_text_file(table_handle: nil, filename: nil, key_index: nil, value_index: nil, vocab_size: nil, delimiter: nil)
        Context.default.execute("InitializeTableFromTextFile", [table_handle, filename], key_index: key_index, value_index: value_index, vocab_size: vocab_size, delimiter: delimiter)
      end

      def initialize_table_from_text_file_v2(table_handle: nil, filename: nil, key_index: nil, value_index: nil, vocab_size: nil, delimiter: nil)
        Context.default.execute("InitializeTableFromTextFileV2", [table_handle, filename], key_index: key_index, value_index: value_index, vocab_size: vocab_size, delimiter: delimiter)
      end

      def initialize_table_v2(table_handle: nil, keys: nil, values: nil)
        Context.default.execute("InitializeTableV2", [table_handle, keys, values])
      end

      def inplace_add(x: nil, i: nil, v: nil)
        Context.default.execute("InplaceAdd", [x, i, v])
      end

      def inplace_sub(x: nil, i: nil, v: nil)
        Context.default.execute("InplaceSub", [x, i, v])
      end

      def inplace_update(x: nil, i: nil, v: nil)
        Context.default.execute("InplaceUpdate", [x, i, v])
      end

      def interleave_dataset(input_dataset: nil, other_arguments: nil, cycle_length: nil, block_length: nil, f: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("InterleaveDataset", [input_dataset, other_arguments, cycle_length, block_length], f: f, output_types: output_types, output_shapes: output_shapes)
      end

      def inv(x: nil)
        Context.default.execute("Inv", [x])
      end

      def inv_grad(y: nil, dy: nil)
        Context.default.execute("InvGrad", [y, dy])
      end

      def invert(x: nil)
        Context.default.execute("Invert", [x])
      end

      def invert_permutation(x: nil)
        Context.default.execute("InvertPermutation", [x])
      end

      def is_boosted_trees_ensemble_initialized(tree_ensemble_handle: nil)
        Context.default.execute("IsBoostedTreesEnsembleInitialized", [tree_ensemble_handle])
      end

      def is_boosted_trees_quantile_stream_resource_initialized(quantile_stream_resource_handle: nil)
        Context.default.execute("IsBoostedTreesQuantileStreamResourceInitialized", [quantile_stream_resource_handle])
      end

      def is_finite(x: nil)
        Context.default.execute("IsFinite", [x])
      end

      def is_inf(x: nil)
        Context.default.execute("IsInf", [x])
      end

      def is_nan(x: nil)
        Context.default.execute("IsNan", [x])
      end

      def is_variable_initialized(ref: nil, dtype: nil)
        Context.default.execute("IsVariableInitialized", [ref], dtype: dtype)
      end

      def iterator(shared_name: nil, container: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("Iterator", [], shared_name: shared_name, container: container, output_types: output_types, output_shapes: output_shapes)
      end

      def iterator_from_string_handle(string_handle: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("IteratorFromStringHandle", [string_handle], output_types: output_types, output_shapes: output_shapes)
      end

      def iterator_from_string_handle_v2(string_handle: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("IteratorFromStringHandleV2", [string_handle], output_types: output_types, output_shapes: output_shapes)
      end

      def iterator_get_next(iterator: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("IteratorGetNext", [iterator], output_types: output_types, output_shapes: output_shapes)
      end

      def iterator_get_next_as_optional(iterator: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("IteratorGetNextAsOptional", [iterator], output_types: output_types, output_shapes: output_shapes)
      end

      def iterator_get_next_sync(iterator: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("IteratorGetNextSync", [iterator], output_types: output_types, output_shapes: output_shapes)
      end

      def iterator_to_string_handle(resource_handle: nil)
        Context.default.execute("IteratorToStringHandle", [resource_handle])
      end

      def iterator_v2(shared_name: nil, container: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("IteratorV2", [], shared_name: shared_name, container: container, output_types: output_types, output_shapes: output_shapes)
      end

      def kmc2_chain_initialization(distances: nil, seed: nil)
        Context.default.execute("KMC2ChainInitialization", [distances, seed])
      end

      def kmeans_plus_plus_initialization(points: nil, num_to_sample: nil, seed: nil, num_retries_per_sample: nil)
        Context.default.execute("KmeansPlusPlusInitialization", [points, num_to_sample, seed, num_retries_per_sample])
      end

      def l2_loss(t: nil)
        Context.default.execute("L2Loss", [t])
      end

      def lmdb_reader(container: nil, shared_name: nil)
        Context.default.execute("LMDBReader", [], container: container, shared_name: shared_name)
      end

      def lrn(input: nil, depth_radius: nil, bias: nil, alpha: nil, beta: nil)
        Context.default.execute("LRN", [input], depth_radius: depth_radius, bias: bias, alpha: alpha, beta: beta)
      end

      def lrn_grad(input_grads: nil, input_image: nil, output_image: nil, depth_radius: nil, bias: nil, alpha: nil, beta: nil)
        Context.default.execute("LRNGrad", [input_grads, input_image, output_image], depth_radius: depth_radius, bias: bias, alpha: alpha, beta: beta)
      end

      def leaky_relu(features: nil, alpha: nil)
        Context.default.execute("LeakyRelu", [features], alpha: alpha)
      end

      def leaky_relu_grad(gradients: nil, features: nil, alpha: nil)
        Context.default.execute("LeakyReluGrad", [gradients, features], alpha: alpha)
      end

      def learned_unigram_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
        Context.default.execute("LearnedUnigramCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
      end

      def left_shift(x: nil, y: nil)
        Context.default.execute("LeftShift", [x, y])
      end

      def less(x: nil, y: nil)
        Context.default.execute("Less", [x, y])
      end

      def less_equal(x: nil, y: nil)
        Context.default.execute("LessEqual", [x, y])
      end

      def lgamma(x: nil)
        Context.default.execute("Lgamma", [x])
      end

      def lin_space(start: nil, stop: nil, num: nil)
        Context.default.execute("LinSpace", [start, stop, num])
      end

      def list_diff(x: nil, y: nil, out_idx: nil)
        Context.default.execute("ListDiff", [x, y], out_idx: out_idx)
      end

      def load_and_remap_matrix(ckpt_path: nil, old_tensor_name: nil, row_remapping: nil, col_remapping: nil, initializing_values: nil, num_rows: nil, num_cols: nil, max_rows_in_memory: nil)
        Context.default.execute("LoadAndRemapMatrix", [ckpt_path, old_tensor_name, row_remapping, col_remapping, initializing_values], num_rows: num_rows, num_cols: num_cols, max_rows_in_memory: max_rows_in_memory)
      end

      def load_tpu_embedding_adam_parameters(parameters: nil, momenta: nil, velocities: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingADAMParameters", [parameters, momenta, velocities], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_adam_parameters_grad_accum_debug(parameters: nil, momenta: nil, velocities: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingADAMParametersGradAccumDebug", [parameters, momenta, velocities, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_adadelta_parameters(parameters: nil, accumulators: nil, updates: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingAdadeltaParameters", [parameters, accumulators, updates], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_adadelta_parameters_grad_accum_debug(parameters: nil, accumulators: nil, updates: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingAdadeltaParametersGradAccumDebug", [parameters, accumulators, updates, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_adagrad_parameters(parameters: nil, accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingAdagradParameters", [parameters, accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_adagrad_parameters_grad_accum_debug(parameters: nil, accumulators: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingAdagradParametersGradAccumDebug", [parameters, accumulators, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_centered_rms_prop_parameters(parameters: nil, ms: nil, mom: nil, mg: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingCenteredRMSPropParameters", [parameters, ms, mom, mg], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_ftrl_parameters(parameters: nil, accumulators: nil, linears: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingFTRLParameters", [parameters, accumulators, linears], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_ftrl_parameters_grad_accum_debug(parameters: nil, accumulators: nil, linears: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingFTRLParametersGradAccumDebug", [parameters, accumulators, linears, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_mdl_adagrad_light_parameters(parameters: nil, accumulators: nil, weights: nil, benefits: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingMDLAdagradLightParameters", [parameters, accumulators, weights, benefits], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_momentum_parameters(parameters: nil, momenta: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingMomentumParameters", [parameters, momenta], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_momentum_parameters_grad_accum_debug(parameters: nil, momenta: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingMomentumParametersGradAccumDebug", [parameters, momenta, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_proximal_adagrad_parameters(parameters: nil, accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingProximalAdagradParameters", [parameters, accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(parameters: nil, accumulators: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug", [parameters, accumulators, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_rms_prop_parameters(parameters: nil, ms: nil, mom: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingRMSPropParameters", [parameters, ms, mom], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_rms_prop_parameters_grad_accum_debug(parameters: nil, ms: nil, mom: nil, gradient_accumulators: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingRMSPropParametersGradAccumDebug", [parameters, ms, mom, gradient_accumulators], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def load_tpu_embedding_stochastic_gradient_descent_parameters(parameters: nil, table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("LoadTPUEmbeddingStochasticGradientDescentParameters", [parameters], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def log(x: nil)
        Context.default.execute("Log", [x])
      end

      def log1p(x: nil)
        Context.default.execute("Log1p", [x])
      end

      def log_matrix_determinant(input: nil)
        Context.default.execute("LogMatrixDeterminant", [input])
      end

      def log_softmax(logits: nil)
        Context.default.execute("LogSoftmax", [logits])
      end

      def log_uniform_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
        Context.default.execute("LogUniformCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
      end

      def logical_and(x: nil, y: nil)
        Context.default.execute("LogicalAnd", [x, y])
      end

      def logical_not(x: nil)
        Context.default.execute("LogicalNot", [x])
      end

      def logical_or(x: nil, y: nil)
        Context.default.execute("LogicalOr", [x, y])
      end

      def lookup_table_export(table_handle: nil)
        Context.default.execute("LookupTableExport", [table_handle])
      end

      def lookup_table_export_v2(table_handle: nil)
        Context.default.execute("LookupTableExportV2", [table_handle])
      end

      def lookup_table_find(table_handle: nil, keys: nil, default_value: nil)
        Context.default.execute("LookupTableFind", [table_handle, keys, default_value])
      end

      def lookup_table_find_v2(table_handle: nil, keys: nil, default_value: nil)
        Context.default.execute("LookupTableFindV2", [table_handle, keys, default_value])
      end

      def lookup_table_import(table_handle: nil, keys: nil, values: nil)
        Context.default.execute("LookupTableImport", [table_handle, keys, values])
      end

      def lookup_table_import_v2(table_handle: nil, keys: nil, values: nil)
        Context.default.execute("LookupTableImportV2", [table_handle, keys, values])
      end

      def lookup_table_insert(table_handle: nil, keys: nil, values: nil)
        Context.default.execute("LookupTableInsert", [table_handle, keys, values])
      end

      def lookup_table_insert_v2(table_handle: nil, keys: nil, values: nil)
        Context.default.execute("LookupTableInsertV2", [table_handle, keys, values])
      end

      def lookup_table_remove_v2(table_handle: nil, keys: nil)
        Context.default.execute("LookupTableRemoveV2", [table_handle, keys])
      end

      def lookup_table_size(table_handle: nil)
        Context.default.execute("LookupTableSize", [table_handle])
      end

      def lookup_table_size_v2(table_handle: nil)
        Context.default.execute("LookupTableSizeV2", [table_handle])
      end

      def loop_cond(input: nil)
        Context.default.execute("LoopCond", [input])
      end

      def lower_bound(sorted_inputs: nil, values: nil, out_type: nil)
        Context.default.execute("LowerBound", [sorted_inputs, values], out_type: out_type)
      end

      def lu(input: nil, output_idx_type: nil)
        Context.default.execute("Lu", [input], output_idx_type: output_idx_type)
      end

      def make_iterator(dataset: nil, iterator: nil)
        Context.default.execute("MakeIterator", [dataset, iterator])
      end

      def map_clear(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapClear", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def map_dataset(input_dataset: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil, preserve_cardinality: nil)
        Context.default.execute("MapDataset", [input_dataset, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism, preserve_cardinality: preserve_cardinality)
      end

      def map_defun(arguments: nil, captured_inputs: nil, output_types: nil, output_shapes: nil, f: nil, max_intra_op_parallelism: nil)
        Context.default.execute("MapDefun", [arguments, captured_inputs], output_types: output_types, output_shapes: output_shapes, f: f, max_intra_op_parallelism: max_intra_op_parallelism)
      end

      def map_incomplete_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapIncompleteSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def map_peek(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapPeek", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def map_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def map_stage(key: nil, indices: nil, values: nil, capacity: nil, memory_limit: nil, dtypes: nil, fake_dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapStage", [key, indices, values], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, fake_dtypes: fake_dtypes, container: container, shared_name: shared_name)
      end

      def map_unstage(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapUnstage", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def map_unstage_no_key(indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("MapUnstageNoKey", [indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def mat_mul(a: nil, b: nil, transpose_a: nil, transpose_b: nil)
        Context.default.execute("MatMul", [a, b], transpose_a: transpose_a, transpose_b: transpose_b)
      end

      def matching_files(pattern: nil)
        Context.default.execute("MatchingFiles", [pattern])
      end

      def matrix_band_part(input: nil, num_lower: nil, num_upper: nil)
        Context.default.execute("MatrixBandPart", [input, num_lower, num_upper])
      end

      def matrix_determinant(input: nil)
        Context.default.execute("MatrixDeterminant", [input])
      end

      def matrix_diag(diagonal: nil)
        Context.default.execute("MatrixDiag", [diagonal])
      end

      def matrix_diag_part(input: nil)
        Context.default.execute("MatrixDiagPart", [input])
      end

      def matrix_exponential(input: nil)
        Context.default.execute("MatrixExponential", [input])
      end

      def matrix_inverse(input: nil, adjoint: nil)
        Context.default.execute("MatrixInverse", [input], adjoint: adjoint)
      end

      def matrix_logarithm(input: nil)
        Context.default.execute("MatrixLogarithm", [input])
      end

      def matrix_set_diag(input: nil, diagonal: nil)
        Context.default.execute("MatrixSetDiag", [input, diagonal])
      end

      def matrix_solve(matrix: nil, rhs: nil, adjoint: nil)
        Context.default.execute("MatrixSolve", [matrix, rhs], adjoint: adjoint)
      end

      def matrix_solve_ls(matrix: nil, rhs: nil, l2_regularizer: nil, fast: nil)
        Context.default.execute("MatrixSolveLs", [matrix, rhs, l2_regularizer], fast: fast)
      end

      def matrix_square_root(input: nil)
        Context.default.execute("MatrixSquareRoot", [input])
      end

      def matrix_triangular_solve(matrix: nil, rhs: nil, lower: nil, adjoint: nil)
        Context.default.execute("MatrixTriangularSolve", [matrix, rhs], lower: lower, adjoint: adjoint)
      end

      def max(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("Max", [input, reduction_indices], keep_dims: keep_dims)
      end

      def max_pool(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPool", [input], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def max_pool3d(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPool3D", [input], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def max_pool3d_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPool3DGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def max_pool3d_grad_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPool3DGradGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def max_pool_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPoolGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def max_pool_grad_grad(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPoolGradGrad", [orig_input, orig_output, grad], ksize: ksize, strides: strides, padding: padding, data_format: data_format)
      end

      def max_pool_grad_grad_v2(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPoolGradGradV2", [orig_input, orig_output, grad, ksize, strides], padding: padding, data_format: data_format)
      end

      def max_pool_grad_grad_with_argmax(input: nil, grad: nil, argmax: nil, ksize: nil, strides: nil, padding: nil, include_batch_in_index: nil)
        Context.default.execute("MaxPoolGradGradWithArgmax", [input, grad, argmax], ksize: ksize, strides: strides, padding: padding, include_batch_in_index: include_batch_in_index)
      end

      def max_pool_grad_v2(orig_input: nil, orig_output: nil, grad: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPoolGradV2", [orig_input, orig_output, grad, ksize, strides], padding: padding, data_format: data_format)
      end

      def max_pool_grad_with_argmax(input: nil, grad: nil, argmax: nil, ksize: nil, strides: nil, padding: nil, include_batch_in_index: nil)
        Context.default.execute("MaxPoolGradWithArgmax", [input, grad, argmax], ksize: ksize, strides: strides, padding: padding, include_batch_in_index: include_batch_in_index)
      end

      def max_pool_v2(input: nil, ksize: nil, strides: nil, padding: nil, data_format: nil)
        Context.default.execute("MaxPoolV2", [input, ksize, strides], padding: padding, data_format: data_format)
      end

      def max_pool_with_argmax(input: nil, ksize: nil, strides: nil, padding: nil, include_batch_in_index: nil)
        Context.default.execute("MaxPoolWithArgmax", [input], ksize: ksize, strides: strides, padding: padding, include_batch_in_index: include_batch_in_index)
      end

      def maximum(x: nil, y: nil)
        Context.default.execute("Maximum", [x, y])
      end

      def mean(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("Mean", [input, reduction_indices], keep_dims: keep_dims)
      end

      def merge(inputs: nil)
        Context.default.execute("Merge", [inputs])
      end

      def merge_summary(inputs: nil)
        Context.default.execute("MergeSummary", [inputs])
      end

      def merge_v2_checkpoints(checkpoint_prefixes: nil, destination_prefix: nil, delete_old_dirs: nil)
        Context.default.execute("MergeV2Checkpoints", [checkpoint_prefixes, destination_prefix], delete_old_dirs: delete_old_dirs)
      end

      def mfcc(spectrogram: nil, sample_rate: nil, upper_frequency_limit: nil, lower_frequency_limit: nil, filterbank_channel_count: nil, dct_coefficient_count: nil)
        Context.default.execute("Mfcc", [spectrogram, sample_rate], upper_frequency_limit: upper_frequency_limit, lower_frequency_limit: lower_frequency_limit, filterbank_channel_count: filterbank_channel_count, dct_coefficient_count: dct_coefficient_count)
      end

      def min(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("Min", [input, reduction_indices], keep_dims: keep_dims)
      end

      def minimum(x: nil, y: nil)
        Context.default.execute("Minimum", [x, y])
      end

      def mirror_pad(input: nil, paddings: nil, mode: nil)
        Context.default.execute("MirrorPad", [input, paddings], mode: mode)
      end

      def mirror_pad_grad(input: nil, paddings: nil, mode: nil)
        Context.default.execute("MirrorPadGrad", [input, paddings], mode: mode)
      end

      def mod(x: nil, y: nil)
        Context.default.execute("Mod", [x, y])
      end

      def model_dataset(input_dataset: nil, cpu_budget: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ModelDataset", [input_dataset], cpu_budget: cpu_budget, output_types: output_types, output_shapes: output_shapes)
      end

      def mul(x: nil, y: nil)
        Context.default.execute("Mul", [x, y])
      end

      def mul_no_nan(x: nil, y: nil)
        Context.default.execute("MulNoNan", [x, y])
      end

      def multi_device_iterator(devices: nil, shared_name: nil, container: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("MultiDeviceIterator", [], devices: devices, shared_name: shared_name, container: container, output_types: output_types, output_shapes: output_shapes)
      end

      def multi_device_iterator_from_string_handle(string_handle: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("MultiDeviceIteratorFromStringHandle", [string_handle], output_types: output_types, output_shapes: output_shapes)
      end

      def multi_device_iterator_get_next_from_shard(multi_device_iterator: nil, shard_num: nil, incarnation_id: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("MultiDeviceIteratorGetNextFromShard", [multi_device_iterator, shard_num, incarnation_id], output_types: output_types, output_shapes: output_shapes)
      end

      def multi_device_iterator_init(dataset: nil, multi_device_iterator: nil, max_buffer_size: nil)
        Context.default.execute("MultiDeviceIteratorInit", [dataset, multi_device_iterator, max_buffer_size])
      end

      def multi_device_iterator_to_string_handle(multi_device_iterator: nil)
        Context.default.execute("MultiDeviceIteratorToStringHandle", [multi_device_iterator])
      end

      def multinomial(logits: nil, num_samples: nil, seed: nil, seed2: nil, output_dtype: nil)
        Context.default.execute("Multinomial", [logits, num_samples], seed: seed, seed2: seed2, output_dtype: output_dtype)
      end

      def mutable_dense_hash_table(empty_key: nil, container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil, initial_num_buckets: nil, max_load_factor: nil)
        Context.default.execute("MutableDenseHashTable", [empty_key], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape, initial_num_buckets: initial_num_buckets, max_load_factor: max_load_factor)
      end

      def mutable_dense_hash_table_v2(empty_key: nil, deleted_key: nil, container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil, initial_num_buckets: nil, max_load_factor: nil)
        Context.default.execute("MutableDenseHashTableV2", [empty_key, deleted_key], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape, initial_num_buckets: initial_num_buckets, max_load_factor: max_load_factor)
      end

      def mutable_hash_table(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
        Context.default.execute("MutableHashTable", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
      end

      def mutable_hash_table_of_tensors(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil)
        Context.default.execute("MutableHashTableOfTensors", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape)
      end

      def mutable_hash_table_of_tensors_v2(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil, value_shape: nil)
        Context.default.execute("MutableHashTableOfTensorsV2", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype, value_shape: value_shape)
      end

      def mutable_hash_table_v2(container: nil, shared_name: nil, use_node_name_sharing: nil, key_dtype: nil, value_dtype: nil)
        Context.default.execute("MutableHashTableV2", [], container: container, shared_name: shared_name, use_node_name_sharing: use_node_name_sharing, key_dtype: key_dtype, value_dtype: value_dtype)
      end

      def mutex_lock(mutex: nil)
        Context.default.execute("MutexLock", [mutex])
      end

      def mutex_v2(container: nil, shared_name: nil)
        Context.default.execute("MutexV2", [], container: container, shared_name: shared_name)
      end

      def nccl_all_reduce(input: nil, reduction: nil, num_devices: nil, shared_name: nil)
        Context.default.execute("NcclAllReduce", [input], reduction: reduction, num_devices: num_devices, shared_name: shared_name)
      end

      def nccl_broadcast(input: nil, shape: nil)
        Context.default.execute("NcclBroadcast", [input], shape: shape)
      end

      def nccl_reduce(input: nil, reduction: nil, num_devices: nil)
        Context.default.execute("NcclReduce", [input], reduction: reduction, num_devices: num_devices)
      end

      def nearest_neighbors(points: nil, centers: nil, k: nil)
        Context.default.execute("NearestNeighbors", [points, centers, k])
      end

      def neg(x: nil)
        Context.default.execute("Neg", [x])
      end

      def neg_train(w_in: nil, w_out: nil, examples: nil, labels: nil, lr: nil, vocab_count: nil, num_negative_samples: nil)
        Context.default.execute("NegTrain", [w_in, w_out, examples, labels, lr], vocab_count: vocab_count, num_negative_samples: num_negative_samples)
      end

      def next_after(x1: nil, x2: nil)
        Context.default.execute("NextAfter", [x1, x2])
      end

      def next_iteration(data: nil)
        Context.default.execute("NextIteration", [data])
      end

      def no_op
        Context.default.execute("NoOp", [])
      end

      def non_deterministic_ints(shape: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("NonDeterministicInts", [shape], dtype: dtype, shape_dtype: shape_dtype)
      end

      def non_max_suppression(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil)
        Context.default.execute("NonMaxSuppression", [boxes, scores, max_output_size], iou_threshold: iou_threshold)
      end

      def non_max_suppression_v2(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil)
        Context.default.execute("NonMaxSuppressionV2", [boxes, scores, max_output_size, iou_threshold])
      end

      def non_max_suppression_v3(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil, score_threshold: nil)
        Context.default.execute("NonMaxSuppressionV3", [boxes, scores, max_output_size, iou_threshold, score_threshold])
      end

      def non_max_suppression_v4(boxes: nil, scores: nil, max_output_size: nil, iou_threshold: nil, score_threshold: nil, pad_to_max_output_size: nil)
        Context.default.execute("NonMaxSuppressionV4", [boxes, scores, max_output_size, iou_threshold, score_threshold], pad_to_max_output_size: pad_to_max_output_size)
      end

      def non_max_suppression_with_overlaps(overlaps: nil, scores: nil, max_output_size: nil, overlap_threshold: nil, score_threshold: nil)
        Context.default.execute("NonMaxSuppressionWithOverlaps", [overlaps, scores, max_output_size, overlap_threshold, score_threshold])
      end

      def not_equal(x: nil, y: nil)
        Context.default.execute("NotEqual", [x, y])
      end

      def nth_element(input: nil, n: nil, reverse: nil)
        Context.default.execute("NthElement", [input, n], reverse: reverse)
      end

      def one_hot(indices: nil, depth: nil, on_value: nil, off_value: nil, axis: nil)
        Context.default.execute("OneHot", [indices, depth, on_value, off_value], axis: axis)
      end

      def one_shot_iterator(dataset_factory: nil, output_types: nil, output_shapes: nil, container: nil, shared_name: nil)
        Context.default.execute("OneShotIterator", [], dataset_factory: dataset_factory, output_types: output_types, output_shapes: output_shapes, container: container, shared_name: shared_name)
      end

      def ones_like(x: nil)
        Context.default.execute("OnesLike", [x])
      end

      def optimize_dataset(input_dataset: nil, optimizations: nil, output_types: nil, output_shapes: nil, optimization_configs: nil)
        Context.default.execute("OptimizeDataset", [input_dataset, optimizations], output_types: output_types, output_shapes: output_shapes, optimization_configs: optimization_configs)
      end

      def optional_from_value(components: nil)
        Context.default.execute("OptionalFromValue", [components])
      end

      def optional_get_value(optional: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("OptionalGetValue", [optional], output_types: output_types, output_shapes: output_shapes)
      end

      def optional_has_value(optional: nil)
        Context.default.execute("OptionalHasValue", [optional])
      end

      def optional_none
        Context.default.execute("OptionalNone", [])
      end

      def ordered_map_clear(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapClear", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def ordered_map_incomplete_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapIncompleteSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def ordered_map_peek(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapPeek", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def ordered_map_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def ordered_map_stage(key: nil, indices: nil, values: nil, capacity: nil, memory_limit: nil, dtypes: nil, fake_dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapStage", [key, indices, values], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, fake_dtypes: fake_dtypes, container: container, shared_name: shared_name)
      end

      def ordered_map_unstage(key: nil, indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapUnstage", [key, indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def ordered_map_unstage_no_key(indices: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("OrderedMapUnstageNoKey", [indices], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def outfeed_dequeue(dtype: nil, shape: nil, device_ordinal: nil)
        Context.default.execute("OutfeedDequeue", [], dtype: dtype, shape: shape, device_ordinal: device_ordinal)
      end

      def outfeed_dequeue_tuple(dtypes: nil, shapes: nil, device_ordinal: nil)
        Context.default.execute("OutfeedDequeueTuple", [], dtypes: dtypes, shapes: shapes, device_ordinal: device_ordinal)
      end

      def outfeed_enqueue(input: nil, dtype: nil)
        Context.default.execute("OutfeedEnqueue", [input], dtype: dtype)
      end

      def outfeed_enqueue_tuple(inputs: nil, dtypes: nil)
        Context.default.execute("OutfeedEnqueueTuple", [inputs], dtypes: dtypes)
      end

      def pack(values: nil, axis: nil)
        Context.default.execute("Pack", [values], axis: axis)
      end

      def pad(input: nil, paddings: nil)
        Context.default.execute("Pad", [input, paddings])
      end

      def pad_v2(input: nil, paddings: nil, constant_values: nil)
        Context.default.execute("PadV2", [input, paddings, constant_values])
      end

      def padded_batch_dataset(input_dataset: nil, batch_size: nil, padded_shapes: nil, padding_values: nil, output_shapes: nil)
        Context.default.execute("PaddedBatchDataset", [input_dataset, batch_size, padded_shapes, padding_values], output_shapes: output_shapes)
      end

      def padded_batch_dataset_v2(input_dataset: nil, batch_size: nil, padded_shapes: nil, padding_values: nil, drop_remainder: nil, parallel_copy: nil, output_shapes: nil)
        Context.default.execute("PaddedBatchDatasetV2", [input_dataset, batch_size, padded_shapes, padding_values, drop_remainder], parallel_copy: parallel_copy, output_shapes: output_shapes)
      end

      def padding_fifo_queue(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("PaddingFIFOQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def padding_fifo_queue_v2(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("PaddingFIFOQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def parallel_concat(values: nil, shape: nil)
        Context.default.execute("ParallelConcat", [values], shape: shape)
      end

      def parallel_dynamic_stitch(indices: nil, data: nil)
        Context.default.execute("ParallelDynamicStitch", [indices, data])
      end

      def parallel_interleave_dataset_v2(input_dataset: nil, other_arguments: nil, cycle_length: nil, block_length: nil, num_parallel_calls: nil, f: nil, output_types: nil, output_shapes: nil, sloppy: nil)
        Context.default.execute("ParallelInterleaveDatasetV2", [input_dataset, other_arguments, cycle_length, block_length, num_parallel_calls], f: f, output_types: output_types, output_shapes: output_shapes, sloppy: sloppy)
      end

      def parallel_map_dataset(input_dataset: nil, other_arguments: nil, num_parallel_calls: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil, sloppy: nil, preserve_cardinality: nil)
        Context.default.execute("ParallelMapDataset", [input_dataset, other_arguments, num_parallel_calls], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism, sloppy: sloppy, preserve_cardinality: preserve_cardinality)
      end

      def parameterized_truncated_normal(shape: nil, means: nil, stdevs: nil, minvals: nil, maxvals: nil, seed: nil, seed2: nil, dtype: nil)
        Context.default.execute("ParameterizedTruncatedNormal", [shape, means, stdevs, minvals, maxvals], seed: seed, seed2: seed2, dtype: dtype)
      end

      def parse_example(serialized: nil, names: nil, sparse_keys: nil, dense_keys: nil, dense_defaults: nil, sparse_types: nil, dense_shapes: nil)
        Context.default.execute("ParseExample", [serialized, names, sparse_keys, dense_keys, dense_defaults], sparse_types: sparse_types, dense_shapes: dense_shapes)
      end

      def parse_sequence_example(serialized: nil, debug_name: nil, context_dense_defaults: nil, feature_list_dense_missing_assumed_empty: nil, context_sparse_keys: nil, context_dense_keys: nil, feature_list_sparse_keys: nil, feature_list_dense_keys: nil, context_sparse_types: nil, feature_list_dense_types: nil, context_dense_shapes: nil, feature_list_sparse_types: nil, feature_list_dense_shapes: nil)
        Context.default.execute("ParseSequenceExample", [serialized, debug_name, context_dense_defaults], feature_list_dense_missing_assumed_empty: feature_list_dense_missing_assumed_empty, context_sparse_keys: context_sparse_keys, context_dense_keys: context_dense_keys, feature_list_sparse_keys: feature_list_sparse_keys, feature_list_dense_keys: feature_list_dense_keys, context_sparse_types: context_sparse_types, feature_list_dense_types: feature_list_dense_types, context_dense_shapes: context_dense_shapes, feature_list_sparse_types: feature_list_sparse_types, feature_list_dense_shapes: feature_list_dense_shapes)
      end

      def parse_single_example(serialized: nil, dense_defaults: nil, num_sparse: nil, sparse_keys: nil, dense_keys: nil, sparse_types: nil, dense_shapes: nil)
        Context.default.execute("ParseSingleExample", [serialized, dense_defaults], num_sparse: num_sparse, sparse_keys: sparse_keys, dense_keys: dense_keys, sparse_types: sparse_types, dense_shapes: dense_shapes)
      end

      def parse_single_sequence_example(serialized: nil, feature_list_dense_missing_assumed_empty: nil, context_sparse_keys: nil, context_dense_keys: nil, feature_list_sparse_keys: nil, feature_list_dense_keys: nil, context_dense_defaults: nil, debug_name: nil, context_sparse_types: nil, feature_list_dense_types: nil, context_dense_shapes: nil, feature_list_sparse_types: nil, feature_list_dense_shapes: nil)
        Context.default.execute("ParseSingleSequenceExample", [serialized, feature_list_dense_missing_assumed_empty, context_sparse_keys, context_dense_keys, feature_list_sparse_keys, feature_list_dense_keys, context_dense_defaults, debug_name], context_sparse_types: context_sparse_types, feature_list_dense_types: feature_list_dense_types, context_dense_shapes: context_dense_shapes, feature_list_sparse_types: feature_list_sparse_types, feature_list_dense_shapes: feature_list_dense_shapes)
      end

      def parse_tensor(serialized: nil, out_type: nil)
        Context.default.execute("ParseTensor", [serialized], out_type: out_type)
      end

      def partitioned_call(args: nil, f: nil, config: nil, config_proto: nil, executor_type: nil)
        Context.default.execute("PartitionedCall", [args], f: f, config: config, config_proto: config_proto, executor_type: executor_type)
      end

      def placeholder(dtype: nil, shape: nil)
        Context.default.execute("Placeholder", [], dtype: dtype, shape: shape)
      end

      def placeholder_v2(dtype: nil, shape: nil)
        Context.default.execute("PlaceholderV2", [], dtype: dtype, shape: shape)
      end

      def placeholder_with_default(input: nil, dtype: nil, shape: nil)
        Context.default.execute("PlaceholderWithDefault", [input], dtype: dtype, shape: shape)
      end

      def polygamma(a: nil, x: nil)
        Context.default.execute("Polygamma", [a, x])
      end

      def population_count(x: nil)
        Context.default.execute("PopulationCount", [x])
      end

      def pow(x: nil, y: nil)
        Context.default.execute("Pow", [x, y])
      end

      def prefetch_dataset(input_dataset: nil, buffer_size: nil, output_types: nil, output_shapes: nil, slack_period: nil)
        Context.default.execute("PrefetchDataset", [input_dataset, buffer_size], output_types: output_types, output_shapes: output_shapes, slack_period: slack_period)
      end

      def prelinearize(input: nil, dtype: nil, shape: nil, layout: nil)
        Context.default.execute("Prelinearize", [input], dtype: dtype, shape: shape, layout: layout)
      end

      def prelinearize_tuple(inputs: nil, dtypes: nil, shapes: nil, layouts: nil)
        Context.default.execute("PrelinearizeTuple", [inputs], dtypes: dtypes, shapes: shapes, layouts: layouts)
      end

      def prevent_gradient(input: nil, message: nil)
        Context.default.execute("PreventGradient", [input], message: message)
      end

      def print(input: nil, data: nil, message: nil, first_n: nil, summarize: nil)
        Context.default.execute("Print", [input, data], message: message, first_n: first_n, summarize: summarize)
      end

      def print_v2(input: nil, output_stream: nil, stop: nil)
        Context.default.execute("PrintV2", [input], output_stream: output_stream, stop: stop)
      end

      def priority_queue(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("PriorityQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def priority_queue_v2(component_types: nil, shapes: nil, capacity: nil, container: nil, shared_name: nil)
        Context.default.execute("PriorityQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, container: container, shared_name: shared_name)
      end

      def prod(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("Prod", [input, reduction_indices], keep_dims: keep_dims)
      end

      def py_func(input: nil, token: nil)
        Context.default.execute("PyFunc", [input], token: token)
      end

      def py_func_stateless(input: nil, token: nil)
        Context.default.execute("PyFuncStateless", [input], token: token)
      end

      def qr(input: nil, full_matrices: nil)
        Context.default.execute("Qr", [input], full_matrices: full_matrices)
      end

      def quantize_and_dequantize(input: nil, signed_input: nil, num_bits: nil, range_given: nil, input_min: nil, input_max: nil)
        Context.default.execute("QuantizeAndDequantize", [input], signed_input: signed_input, num_bits: num_bits, range_given: range_given, input_min: input_min, input_max: input_max)
      end

      def quantize_and_dequantize_v2(input: nil, input_min: nil, input_max: nil, signed_input: nil, num_bits: nil, range_given: nil, round_mode: nil)
        Context.default.execute("QuantizeAndDequantizeV2", [input, input_min, input_max], signed_input: signed_input, num_bits: num_bits, range_given: range_given, round_mode: round_mode)
      end

      def quantize_and_dequantize_v3(input: nil, input_min: nil, input_max: nil, num_bits: nil, signed_input: nil, range_given: nil)
        Context.default.execute("QuantizeAndDequantizeV3", [input, input_min, input_max, num_bits], signed_input: signed_input, range_given: range_given)
      end

      def quantize_down_and_shrink_range(input: nil, input_min: nil, input_max: nil, out_type: nil)
        Context.default.execute("QuantizeDownAndShrinkRange", [input, input_min, input_max], out_type: out_type)
      end

      def quantize_v2(input: nil, min_range: nil, max_range: nil, mode: nil, round_mode: nil)
        Context.default.execute("QuantizeV2", [input, min_range, max_range], mode: mode, round_mode: round_mode)
      end

      def quantized_add(x: nil, y: nil, min_x: nil, max_x: nil, min_y: nil, max_y: nil)
        Context.default.execute("QuantizedAdd", [x, y, min_x, max_x, min_y, max_y])
      end

      def quantized_avg_pool(input: nil, min_input: nil, max_input: nil, ksize: nil, strides: nil, padding: nil)
        Context.default.execute("QuantizedAvgPool", [input, min_input, max_input], ksize: ksize, strides: strides, padding: padding)
      end

      def quantized_batch_norm_with_global_normalization(t: nil, t_min: nil, t_max: nil, m: nil, m_min: nil, m_max: nil, v: nil, v_min: nil, v_max: nil, beta: nil, beta_min: nil, beta_max: nil, gamma: nil, gamma_min: nil, gamma_max: nil, out_type: nil, variance_epsilon: nil, scale_after_normalization: nil)
        Context.default.execute("QuantizedBatchNormWithGlobalNormalization", [t, t_min, t_max, m, m_min, m_max, v, v_min, v_max, beta, beta_min, beta_max, gamma, gamma_min, gamma_max], out_type: out_type, variance_epsilon: variance_epsilon, scale_after_normalization: scale_after_normalization)
      end

      def quantized_bias_add(input: nil, bias: nil, min_input: nil, max_input: nil, min_bias: nil, max_bias: nil, out_type: nil)
        Context.default.execute("QuantizedBiasAdd", [input, bias, min_input, max_input, min_bias, max_bias], out_type: out_type)
      end

      def quantized_concat(concat_dim: nil, values: nil, input_mins: nil, input_maxes: nil)
        Context.default.execute("QuantizedConcat", [concat_dim, values, input_mins, input_maxes])
      end

      def quantized_conv2d(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("QuantizedConv2D", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
      end

      def quantized_conv2d_and_relu(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DAndRelu", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_and_relu_and_requantize(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DAndReluAndRequantize", [input, filter, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_and_requantize(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DAndRequantize", [input, filter, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_per_channel(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("QuantizedConv2DPerChannel", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
      end

      def quantized_conv2d_with_bias(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBias", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_with_bias_and_relu(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBiasAndRelu", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_with_bias_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBiasAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_with_bias_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBiasAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_with_bias_signed_sum_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, summand: nil, min_summand: nil, max_summand: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBiasSignedSumAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output, summand, min_summand, max_summand], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_with_bias_sum_and_relu(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, summand: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBiasSumAndRelu", [input, filter, bias, min_input, max_input, min_filter, max_filter, summand], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_conv2d_with_bias_sum_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, summand: nil, min_summand: nil, max_summand: nil, out_type: nil, strides: nil, padding: nil, dilations: nil, padding_list: nil)
        Context.default.execute("QuantizedConv2DWithBiasSumAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output, summand, min_summand, max_summand], out_type: out_type, strides: strides, padding: padding, dilations: dilations, padding_list: padding_list)
      end

      def quantized_depthwise_conv2d(input: nil, filter: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("QuantizedDepthwiseConv2D", [input, filter, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
      end

      def quantized_depthwise_conv2d_with_bias(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("QuantizedDepthwiseConv2DWithBias", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
      end

      def quantized_depthwise_conv2d_with_bias_and_relu(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("QuantizedDepthwiseConv2DWithBiasAndRelu", [input, filter, bias, min_input, max_input, min_filter, max_filter], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
      end

      def quantized_depthwise_conv2d_with_bias_and_relu_and_requantize(input: nil, filter: nil, bias: nil, min_input: nil, max_input: nil, min_filter: nil, max_filter: nil, min_freezed_output: nil, max_freezed_output: nil, out_type: nil, strides: nil, padding: nil, dilations: nil)
        Context.default.execute("QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize", [input, filter, bias, min_input, max_input, min_filter, max_filter, min_freezed_output, max_freezed_output], out_type: out_type, strides: strides, padding: padding, dilations: dilations)
      end

      def quantized_instance_norm(x: nil, x_min: nil, x_max: nil, output_range_given: nil, given_y_min: nil, given_y_max: nil, variance_epsilon: nil, min_separation: nil)
        Context.default.execute("QuantizedInstanceNorm", [x, x_min, x_max], output_range_given: output_range_given, given_y_min: given_y_min, given_y_max: given_y_max, variance_epsilon: variance_epsilon, min_separation: min_separation)
      end

      def quantized_mat_mul(a: nil, b: nil, min_a: nil, max_a: nil, min_b: nil, max_b: nil, transpose_a: nil, transpose_b: nil)
        Context.default.execute("QuantizedMatMul", [a, b, min_a, max_a, min_b, max_b], transpose_a: transpose_a, transpose_b: transpose_b)
      end

      def quantized_max_pool(input: nil, min_input: nil, max_input: nil, ksize: nil, strides: nil, padding: nil)
        Context.default.execute("QuantizedMaxPool", [input, min_input, max_input], ksize: ksize, strides: strides, padding: padding)
      end

      def quantized_mul(x: nil, y: nil, min_x: nil, max_x: nil, min_y: nil, max_y: nil)
        Context.default.execute("QuantizedMul", [x, y, min_x, max_x, min_y, max_y])
      end

      def quantized_relu(features: nil, min_features: nil, max_features: nil, out_type: nil)
        Context.default.execute("QuantizedRelu", [features, min_features, max_features], out_type: out_type)
      end

      def quantized_relu6(features: nil, min_features: nil, max_features: nil, out_type: nil)
        Context.default.execute("QuantizedRelu6", [features, min_features, max_features], out_type: out_type)
      end

      def quantized_relu_x(features: nil, max_value: nil, min_features: nil, max_features: nil, out_type: nil)
        Context.default.execute("QuantizedReluX", [features, max_value, min_features, max_features], out_type: out_type)
      end

      def quantized_reshape(tensor: nil, shape: nil, input_min: nil, input_max: nil)
        Context.default.execute("QuantizedReshape", [tensor, shape, input_min, input_max])
      end

      def quantized_resize_bilinear(images: nil, size: nil, min: nil, max: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("QuantizedResizeBilinear", [images, size, min, max], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def queue_close(handle: nil, cancel_pending_enqueues: nil)
        Context.default.execute("QueueClose", [handle], cancel_pending_enqueues: cancel_pending_enqueues)
      end

      def queue_close_v2(handle: nil, cancel_pending_enqueues: nil)
        Context.default.execute("QueueCloseV2", [handle], cancel_pending_enqueues: cancel_pending_enqueues)
      end

      def queue_dequeue(handle: nil, component_types: nil, timeout_ms: nil)
        Context.default.execute("QueueDequeue", [handle], component_types: component_types, timeout_ms: timeout_ms)
      end

      def queue_dequeue_many(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
        Context.default.execute("QueueDequeueMany", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
      end

      def queue_dequeue_many_v2(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
        Context.default.execute("QueueDequeueManyV2", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
      end

      def queue_dequeue_up_to(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
        Context.default.execute("QueueDequeueUpTo", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
      end

      def queue_dequeue_up_to_v2(handle: nil, n: nil, component_types: nil, timeout_ms: nil)
        Context.default.execute("QueueDequeueUpToV2", [handle, n], component_types: component_types, timeout_ms: timeout_ms)
      end

      def queue_dequeue_v2(handle: nil, component_types: nil, timeout_ms: nil)
        Context.default.execute("QueueDequeueV2", [handle], component_types: component_types, timeout_ms: timeout_ms)
      end

      def queue_enqueue(handle: nil, components: nil, timeout_ms: nil)
        Context.default.execute("QueueEnqueue", [handle, components], timeout_ms: timeout_ms)
      end

      def queue_enqueue_many(handle: nil, components: nil, timeout_ms: nil)
        Context.default.execute("QueueEnqueueMany", [handle, components], timeout_ms: timeout_ms)
      end

      def queue_enqueue_many_v2(handle: nil, components: nil, timeout_ms: nil)
        Context.default.execute("QueueEnqueueManyV2", [handle, components], timeout_ms: timeout_ms)
      end

      def queue_enqueue_v2(handle: nil, components: nil, timeout_ms: nil)
        Context.default.execute("QueueEnqueueV2", [handle, components], timeout_ms: timeout_ms)
      end

      def queue_is_closed(handle: nil)
        Context.default.execute("QueueIsClosed", [handle])
      end

      def queue_is_closed_v2(handle: nil)
        Context.default.execute("QueueIsClosedV2", [handle])
      end

      def queue_size(handle: nil)
        Context.default.execute("QueueSize", [handle])
      end

      def queue_size_v2(handle: nil)
        Context.default.execute("QueueSizeV2", [handle])
      end

      def rfft(input: nil, fft_length: nil)
        Context.default.execute("RFFT", [input, fft_length])
      end

      def rfft2d(input: nil, fft_length: nil)
        Context.default.execute("RFFT2D", [input, fft_length])
      end

      def rfft3d(input: nil, fft_length: nil)
        Context.default.execute("RFFT3D", [input, fft_length])
      end

      def rgb_to_hsv(images: nil)
        Context.default.execute("RGBToHSV", [images])
      end

      def ragged_gather(params_nested_splits: nil, params_dense_values: nil, indices: nil)
        Context.default.execute("RaggedGather", [params_nested_splits, params_dense_values, indices])
      end

      def ragged_range(starts: nil, limits: nil, deltas: nil)
        Context.default.execute("RaggedRange", [starts, limits, deltas])
      end

      def ragged_tensor_from_variant(encoded_ragged: nil, input_ragged_rank: nil, output_ragged_rank: nil)
        Context.default.execute("RaggedTensorFromVariant", [encoded_ragged], input_ragged_rank: input_ragged_rank, output_ragged_rank: output_ragged_rank)
      end

      def ragged_tensor_to_sparse(rt_nested_splits: nil, rt_dense_values: nil)
        Context.default.execute("RaggedTensorToSparse", [rt_nested_splits, rt_dense_values])
      end

      def ragged_tensor_to_variant(rt_nested_splits: nil, rt_dense_values: nil, batched_input: nil)
        Context.default.execute("RaggedTensorToVariant", [rt_nested_splits, rt_dense_values], batched_input: batched_input)
      end

      def random_crop(image: nil, size: nil, seed: nil, seed2: nil)
        Context.default.execute("RandomCrop", [image, size], seed: seed, seed2: seed2)
      end

      def random_gamma(shape: nil, alpha: nil, seed: nil, seed2: nil)
        Context.default.execute("RandomGamma", [shape, alpha], seed: seed, seed2: seed2)
      end

      def random_gamma_grad(alpha: nil, sample: nil)
        Context.default.execute("RandomGammaGrad", [alpha, sample])
      end

      def random_poisson(shape: nil, rate: nil, seed: nil, seed2: nil, dtype: nil)
        Context.default.execute("RandomPoisson", [shape, rate], seed: seed, seed2: seed2, dtype: dtype)
      end

      def random_poisson_v2(shape: nil, rate: nil, seed: nil, seed2: nil, dtype: nil)
        Context.default.execute("RandomPoissonV2", [shape, rate], seed: seed, seed2: seed2, dtype: dtype)
      end

      def random_shuffle(value: nil, seed: nil, seed2: nil)
        Context.default.execute("RandomShuffle", [value], seed: seed, seed2: seed2)
      end

      def random_shuffle_queue(component_types: nil, shapes: nil, capacity: nil, min_after_dequeue: nil, seed: nil, seed2: nil, container: nil, shared_name: nil)
        Context.default.execute("RandomShuffleQueue", [], component_types: component_types, shapes: shapes, capacity: capacity, min_after_dequeue: min_after_dequeue, seed: seed, seed2: seed2, container: container, shared_name: shared_name)
      end

      def random_shuffle_queue_v2(component_types: nil, shapes: nil, capacity: nil, min_after_dequeue: nil, seed: nil, seed2: nil, container: nil, shared_name: nil)
        Context.default.execute("RandomShuffleQueueV2", [], component_types: component_types, shapes: shapes, capacity: capacity, min_after_dequeue: min_after_dequeue, seed: seed, seed2: seed2, container: container, shared_name: shared_name)
      end

      def random_standard_normal(shape: nil, seed: nil, seed2: nil, dtype: nil)
        Context.default.execute("RandomStandardNormal", [shape], seed: seed, seed2: seed2, dtype: dtype)
      end

      def random_uniform(shape: nil, seed: nil, seed2: nil, dtype: nil)
        Context.default.execute("RandomUniform", [shape], seed: seed, seed2: seed2, dtype: dtype)
      end

      def random_uniform_int(shape: nil, minval: nil, maxval: nil, seed: nil, seed2: nil)
        Context.default.execute("RandomUniformInt", [shape, minval, maxval], seed: seed, seed2: seed2)
      end

      def range(start: nil, limit: nil, delta: nil)
        Context.default.execute("Range", [start, limit, delta])
      end

      def range_dataset(start: nil, stop: nil, step: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("RangeDataset", [start, stop, step], output_types: output_types, output_shapes: output_shapes)
      end

      def rank(input: nil)
        Context.default.execute("Rank", [input])
      end

      def read_file(filename: nil)
        Context.default.execute("ReadFile", [filename])
      end

      def read_variable_op(resource: nil, dtype: nil)
        Context.default.execute("ReadVariableOp", [resource], dtype: dtype)
      end

      def reader_num_records_produced(reader_handle: nil)
        Context.default.execute("ReaderNumRecordsProduced", [reader_handle])
      end

      def reader_num_records_produced_v2(reader_handle: nil)
        Context.default.execute("ReaderNumRecordsProducedV2", [reader_handle])
      end

      def reader_num_work_units_completed(reader_handle: nil)
        Context.default.execute("ReaderNumWorkUnitsCompleted", [reader_handle])
      end

      def reader_num_work_units_completed_v2(reader_handle: nil)
        Context.default.execute("ReaderNumWorkUnitsCompletedV2", [reader_handle])
      end

      def reader_read(reader_handle: nil, queue_handle: nil)
        Context.default.execute("ReaderRead", [reader_handle, queue_handle])
      end

      def reader_read_up_to(reader_handle: nil, queue_handle: nil, num_records: nil)
        Context.default.execute("ReaderReadUpTo", [reader_handle, queue_handle, num_records])
      end

      def reader_read_up_to_v2(reader_handle: nil, queue_handle: nil, num_records: nil)
        Context.default.execute("ReaderReadUpToV2", [reader_handle, queue_handle, num_records])
      end

      def reader_read_v2(reader_handle: nil, queue_handle: nil)
        Context.default.execute("ReaderReadV2", [reader_handle, queue_handle])
      end

      def reader_reset(reader_handle: nil)
        Context.default.execute("ReaderReset", [reader_handle])
      end

      def reader_reset_v2(reader_handle: nil)
        Context.default.execute("ReaderResetV2", [reader_handle])
      end

      def reader_restore_state(reader_handle: nil, state: nil)
        Context.default.execute("ReaderRestoreState", [reader_handle, state])
      end

      def reader_restore_state_v2(reader_handle: nil, state: nil)
        Context.default.execute("ReaderRestoreStateV2", [reader_handle, state])
      end

      def reader_serialize_state(reader_handle: nil)
        Context.default.execute("ReaderSerializeState", [reader_handle])
      end

      def reader_serialize_state_v2(reader_handle: nil)
        Context.default.execute("ReaderSerializeStateV2", [reader_handle])
      end

      def real(input: nil)
        Context.default.execute("Real", [input])
      end

      def real_div(x: nil, y: nil)
        Context.default.execute("RealDiv", [x, y])
      end

      def reciprocal(x: nil)
        Context.default.execute("Reciprocal", [x])
      end

      def reciprocal_grad(y: nil, dy: nil)
        Context.default.execute("ReciprocalGrad", [y, dy])
      end

      def record_input(file_pattern: nil, file_random_seed: nil, file_shuffle_shift_ratio: nil, file_buffer_size: nil, file_parallelism: nil, batch_size: nil, compression_type: nil)
        Context.default.execute("RecordInput", [], file_pattern: file_pattern, file_random_seed: file_random_seed, file_shuffle_shift_ratio: file_shuffle_shift_ratio, file_buffer_size: file_buffer_size, file_parallelism: file_parallelism, batch_size: batch_size, compression_type: compression_type)
      end

      def recv_tpu_embedding_activations(num_outputs: nil, config: nil)
        Context.default.execute("RecvTPUEmbeddingActivations", [], num_outputs: num_outputs, config: config)
      end

      def reduce_dataset(input_dataset: nil, initial_state: nil, other_arguments: nil, f: nil, output_types: nil, output_shapes: nil, use_inter_op_parallelism: nil)
        Context.default.execute("ReduceDataset", [input_dataset, initial_state, other_arguments], f: f, output_types: output_types, output_shapes: output_shapes, use_inter_op_parallelism: use_inter_op_parallelism)
      end

      def reduce_join(inputs: nil, reduction_indices: nil, keep_dims: nil, separator: nil)
        Context.default.execute("ReduceJoin", [inputs, reduction_indices], keep_dims: keep_dims, separator: separator)
      end

      def ref_enter(data: nil, frame_name: nil, is_constant: nil, parallel_iterations: nil)
        Context.default.execute("RefEnter", [data], frame_name: frame_name, is_constant: is_constant, parallel_iterations: parallel_iterations)
      end

      def ref_exit(data: nil)
        Context.default.execute("RefExit", [data])
      end

      def ref_identity(input: nil)
        Context.default.execute("RefIdentity", [input])
      end

      def ref_merge(inputs: nil)
        Context.default.execute("RefMerge", [inputs])
      end

      def ref_next_iteration(data: nil)
        Context.default.execute("RefNextIteration", [data])
      end

      def ref_select(index: nil, inputs: nil)
        Context.default.execute("RefSelect", [index, inputs])
      end

      def ref_switch(data: nil, pred: nil)
        Context.default.execute("RefSwitch", [data, pred])
      end

      def regex_full_match(input: nil, pattern: nil)
        Context.default.execute("RegexFullMatch", [input, pattern])
      end

      def regex_replace(input: nil, pattern: nil, rewrite: nil, replace_global: nil)
        Context.default.execute("RegexReplace", [input, pattern, rewrite], replace_global: replace_global)
      end

      def relu(features: nil)
        Context.default.execute("Relu", [features])
      end

      def relu6(features: nil)
        Context.default.execute("Relu6", [features])
      end

      def relu6_grad(gradients: nil, features: nil)
        Context.default.execute("Relu6Grad", [gradients, features])
      end

      def relu_grad(gradients: nil, features: nil)
        Context.default.execute("ReluGrad", [gradients, features])
      end

      def remote_call(target: nil, args: nil, f: nil)
        Context.default.execute("RemoteCall", [target, args], f: f)
      end

      def remote_fused_graph_execute(inputs: nil, serialized_remote_fused_graph_execute_info: nil)
        Context.default.execute("RemoteFusedGraphExecute", [inputs], serialized_remote_fused_graph_execute_info: serialized_remote_fused_graph_execute_info)
      end

      def repeat_dataset(input_dataset: nil, count: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("RepeatDataset", [input_dataset, count], output_types: output_types, output_shapes: output_shapes)
      end

      def requantization_range(input: nil, input_min: nil, input_max: nil)
        Context.default.execute("RequantizationRange", [input, input_min, input_max])
      end

      def requantization_range_per_channel(input: nil, input_min: nil, input_max: nil, clip_value_max: nil)
        Context.default.execute("RequantizationRangePerChannel", [input, input_min, input_max], clip_value_max: clip_value_max)
      end

      def requantize(input: nil, input_min: nil, input_max: nil, requested_output_min: nil, requested_output_max: nil, out_type: nil)
        Context.default.execute("Requantize", [input, input_min, input_max, requested_output_min, requested_output_max], out_type: out_type)
      end

      def requantize_per_channel(input: nil, input_min: nil, input_max: nil, requested_output_min: nil, requested_output_max: nil, out_type: nil)
        Context.default.execute("RequantizePerChannel", [input, input_min, input_max, requested_output_min, requested_output_max], out_type: out_type)
      end

      def reshape(tensor: nil, shape: nil)
        Context.default.execute("Reshape", [tensor, shape])
      end

      def resize_area(images: nil, size: nil, align_corners: nil)
        Context.default.execute("ResizeArea", [images, size], align_corners: align_corners)
      end

      def resize_bicubic(images: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("ResizeBicubic", [images, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def resize_bicubic_grad(grads: nil, original_image: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("ResizeBicubicGrad", [grads, original_image], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def resize_bilinear(images: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("ResizeBilinear", [images, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def resize_bilinear_grad(grads: nil, original_image: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("ResizeBilinearGrad", [grads, original_image], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def resize_nearest_neighbor(images: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("ResizeNearestNeighbor", [images, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def resize_nearest_neighbor_grad(grads: nil, size: nil, align_corners: nil, half_pixel_centers: nil)
        Context.default.execute("ResizeNearestNeighborGrad", [grads, size], align_corners: align_corners, half_pixel_centers: half_pixel_centers)
      end

      def resource_apply_ada_max(var: nil, m: nil, v: nil, beta1_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyAdaMax", [var, m, v, beta1_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking)
      end

      def resource_apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad], use_locking: use_locking)
      end

      def resource_apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, use_locking: nil, update_slots: nil)
        Context.default.execute("ResourceApplyAdagrad", [var, accum, lr, grad], use_locking: use_locking, update_slots: update_slots)
      end

      def resource_apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
        Context.default.execute("ResourceApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, lr, l1, l2, global_step], use_locking: use_locking)
      end

      def resource_apply_adam(var: nil, m: nil, v: nil, beta1_power: nil, beta2_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ResourceApplyAdam", [var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def resource_apply_adam_with_amsgrad(var: nil, m: nil, v: nil, vhat: nil, beta1_power: nil, beta2_power: nil, lr: nil, beta1: nil, beta2: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyAdamWithAmsgrad", [var, m, v, vhat, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad], use_locking: use_locking)
      end

      def resource_apply_add_sign(var: nil, m: nil, lr: nil, alpha: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyAddSign", [var, m, lr, alpha, sign_decay, beta, grad], use_locking: use_locking)
      end

      def resource_apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
      end

      def resource_apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("ResourceApplyFtrl", [var, accum, linear, grad, lr, l1, l2, lr_power], use_locking: use_locking)
      end

      def resource_apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("ResourceApplyFtrlV2", [var, accum, linear, grad, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
      end

      def resource_apply_gradient_descent(var: nil, alpha: nil, delta: nil, use_locking: nil)
        Context.default.execute("ResourceApplyGradientDescent", [var, alpha, delta], use_locking: use_locking)
      end

      def resource_apply_keras_momentum(var: nil, accum: nil, lr: nil, grad: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ResourceApplyKerasMomentum", [var, accum, lr, grad, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def resource_apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ResourceApplyMomentum", [var, accum, lr, grad, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def resource_apply_power_sign(var: nil, m: nil, lr: nil, logbase: nil, sign_decay: nil, beta: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyPowerSign", [var, m, lr, logbase, sign_decay, beta, grad], use_locking: use_locking)
      end

      def resource_apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyProximalAdagrad", [var, accum, lr, l1, l2, grad], use_locking: use_locking)
      end

      def resource_apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, delta: nil, use_locking: nil)
        Context.default.execute("ResourceApplyProximalGradientDescent", [var, alpha, l1, l2, delta], use_locking: use_locking)
      end

      def resource_apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, use_locking: nil)
        Context.default.execute("ResourceApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad], use_locking: use_locking)
      end

      def resource_count_up_to(resource: nil, limit: nil)
        Context.default.execute("ResourceCountUpTo", [resource], limit: limit)
      end

      def resource_gather(resource: nil, indices: nil, batch_dims: nil, validate_indices: nil, dtype: nil)
        Context.default.execute("ResourceGather", [resource, indices], batch_dims: batch_dims, validate_indices: validate_indices, dtype: dtype)
      end

      def resource_gather_nd(resource: nil, indices: nil, dtype: nil)
        Context.default.execute("ResourceGatherNd", [resource, indices], dtype: dtype)
      end

      def resource_scatter_add(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterAdd", [resource, indices, updates], dtype: dtype)
      end

      def resource_scatter_div(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterDiv", [resource, indices, updates], dtype: dtype)
      end

      def resource_scatter_max(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterMax", [resource, indices, updates], dtype: dtype)
      end

      def resource_scatter_min(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterMin", [resource, indices, updates], dtype: dtype)
      end

      def resource_scatter_mul(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterMul", [resource, indices, updates], dtype: dtype)
      end

      def resource_scatter_nd_add(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ResourceScatterNdAdd", [ref, indices, updates], use_locking: use_locking)
      end

      def resource_scatter_nd_sub(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ResourceScatterNdSub", [ref, indices, updates], use_locking: use_locking)
      end

      def resource_scatter_nd_update(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ResourceScatterNdUpdate", [ref, indices, updates], use_locking: use_locking)
      end

      def resource_scatter_sub(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterSub", [resource, indices, updates], dtype: dtype)
      end

      def resource_scatter_update(resource: nil, indices: nil, updates: nil, dtype: nil)
        Context.default.execute("ResourceScatterUpdate", [resource, indices, updates], dtype: dtype)
      end

      def resource_sparse_apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad, indices], use_locking: use_locking)
      end

      def resource_sparse_apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, use_locking: nil, update_slots: nil)
        Context.default.execute("ResourceSparseApplyAdagrad", [var, accum, lr, grad, indices], use_locking: use_locking, update_slots: update_slots)
      end

      def resource_sparse_apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step], use_locking: use_locking)
      end

      def resource_sparse_apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
      end

      def resource_sparse_apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyFtrl", [var, accum, linear, grad, indices, lr, l1, l2, lr_power], use_locking: use_locking)
      end

      def resource_sparse_apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyFtrlV2", [var, accum, linear, grad, indices, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
      end

      def resource_sparse_apply_keras_momentum(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ResourceSparseApplyKerasMomentum", [var, accum, lr, grad, indices, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def resource_sparse_apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("ResourceSparseApplyMomentum", [var, accum, lr, grad, indices, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def resource_sparse_apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyProximalAdagrad", [var, accum, lr, l1, l2, grad, indices], use_locking: use_locking)
      end

      def resource_sparse_apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyProximalGradientDescent", [var, alpha, l1, l2, grad, indices], use_locking: use_locking)
      end

      def resource_sparse_apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("ResourceSparseApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
      end

      def resource_strided_slice_assign(ref: nil, start: nil, stop: nil, strides: nil, value: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
        Context.default.execute("ResourceStridedSliceAssign", [ref, start, stop, strides, value], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
      end

      def restore(file_pattern: nil, tensor_name: nil, dt: nil, preferred_shard: nil)
        Context.default.execute("Restore", [file_pattern, tensor_name], dt: dt, preferred_shard: preferred_shard)
      end

      def restore_slice(file_pattern: nil, tensor_name: nil, shape_and_slice: nil, dt: nil, preferred_shard: nil)
        Context.default.execute("RestoreSlice", [file_pattern, tensor_name, shape_and_slice], dt: dt, preferred_shard: preferred_shard)
      end

      def restore_v2(prefix: nil, tensor_names: nil, shape_and_slices: nil, dtypes: nil)
        Context.default.execute("RestoreV2", [prefix, tensor_names, shape_and_slices], dtypes: dtypes)
      end

      def retrieve_tpu_embedding_adam_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingADAMParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_adam_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingADAMParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_adadelta_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingAdadeltaParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_adadelta_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_adagrad_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingAdagradParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_adagrad_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingAdagradParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_centered_rms_prop_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingCenteredRMSPropParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_ftrl_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingFTRLParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_ftrl_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingFTRLParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_mdl_adagrad_light_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingMDLAdagradLightParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_momentum_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingMomentumParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_momentum_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingMomentumParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_proximal_adagrad_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingProximalAdagradParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_proximal_adagrad_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_rms_prop_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingRMSPropParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_rms_prop_parameters_grad_accum_debug(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def retrieve_tpu_embedding_stochastic_gradient_descent_parameters(table_id: nil, table_name: nil, num_shards: nil, shard_id: nil)
        Context.default.execute("RetrieveTPUEmbeddingStochasticGradientDescentParameters", [], table_id: table_id, table_name: table_name, num_shards: num_shards, shard_id: shard_id)
      end

      def reverse(tensor: nil, dims: nil)
        Context.default.execute("Reverse", [tensor, dims])
      end

      def reverse_sequence(input: nil, seq_lengths: nil, seq_dim: nil, batch_dim: nil)
        Context.default.execute("ReverseSequence", [input, seq_lengths], seq_dim: seq_dim, batch_dim: batch_dim)
      end

      def reverse_v2(tensor: nil, axis: nil)
        Context.default.execute("ReverseV2", [tensor, axis])
      end

      def right_shift(x: nil, y: nil)
        Context.default.execute("RightShift", [x, y])
      end

      def rint(x: nil)
        Context.default.execute("Rint", [x])
      end

      def rng_skip(resource: nil, algorithm: nil, delta: nil)
        Context.default.execute("RngSkip", [resource, algorithm, delta])
      end

      def roll(input: nil, shift: nil, axis: nil)
        Context.default.execute("Roll", [input, shift, axis])
      end

      def round(x: nil)
        Context.default.execute("Round", [x])
      end

      def rpc(address: nil, method: nil, request: nil, protocol: nil, fail_fast: nil, timeout_in_ms: nil)
        Context.default.execute("Rpc", [address, method, request], protocol: protocol, fail_fast: fail_fast, timeout_in_ms: timeout_in_ms)
      end

      def rsqrt(x: nil)
        Context.default.execute("Rsqrt", [x])
      end

      def rsqrt_grad(y: nil, dy: nil)
        Context.default.execute("RsqrtGrad", [y, dy])
      end

      def sample_distorted_bounding_box(image_size: nil, bounding_boxes: nil, seed: nil, seed2: nil, min_object_covered: nil, aspect_ratio_range: nil, area_range: nil, max_attempts: nil, use_image_if_no_bounding_boxes: nil)
        Context.default.execute("SampleDistortedBoundingBox", [image_size, bounding_boxes], seed: seed, seed2: seed2, min_object_covered: min_object_covered, aspect_ratio_range: aspect_ratio_range, area_range: area_range, max_attempts: max_attempts, use_image_if_no_bounding_boxes: use_image_if_no_bounding_boxes)
      end

      def sample_distorted_bounding_box_v2(image_size: nil, bounding_boxes: nil, min_object_covered: nil, seed: nil, seed2: nil, aspect_ratio_range: nil, area_range: nil, max_attempts: nil, use_image_if_no_bounding_boxes: nil)
        Context.default.execute("SampleDistortedBoundingBoxV2", [image_size, bounding_boxes, min_object_covered], seed: seed, seed2: seed2, aspect_ratio_range: aspect_ratio_range, area_range: area_range, max_attempts: max_attempts, use_image_if_no_bounding_boxes: use_image_if_no_bounding_boxes)
      end

      def sampling_dataset(input_dataset: nil, rate: nil, seed: nil, seed2: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("SamplingDataset", [input_dataset, rate, seed, seed2], output_types: output_types, output_shapes: output_shapes)
      end

      def save(filename: nil, tensor_names: nil, data: nil)
        Context.default.execute("Save", [filename, tensor_names, data])
      end

      def save_slices(filename: nil, tensor_names: nil, shapes_and_slices: nil, data: nil)
        Context.default.execute("SaveSlices", [filename, tensor_names, shapes_and_slices, data])
      end

      def save_v2(prefix: nil, tensor_names: nil, shape_and_slices: nil, tensors: nil, dtypes: nil)
        Context.default.execute("SaveV2", [prefix, tensor_names, shape_and_slices, tensors], dtypes: dtypes)
      end

      def scalar_summary(tags: nil, values: nil)
        Context.default.execute("ScalarSummary", [tags, values])
      end

      def scale_and_translate(images: nil, size: nil, scale: nil, translation: nil, kernel_type: nil, antialias: nil)
        Context.default.execute("ScaleAndTranslate", [images, size, scale, translation], kernel_type: kernel_type, antialias: antialias)
      end

      def scale_and_translate_grad(grads: nil, original_image: nil, scale: nil, translation: nil, kernel_type: nil, antialias: nil)
        Context.default.execute("ScaleAndTranslateGrad", [grads, original_image, scale, translation], kernel_type: kernel_type, antialias: antialias)
      end

      def scatter_add(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterAdd", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_div(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterDiv", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_max(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterMax", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_min(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterMin", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_mul(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterMul", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_nd(indices: nil, updates: nil, shape: nil)
        Context.default.execute("ScatterNd", [indices, updates, shape])
      end

      def scatter_nd_add(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterNdAdd", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_nd_non_aliasing_add(input: nil, indices: nil, updates: nil)
        Context.default.execute("ScatterNdNonAliasingAdd", [input, indices, updates])
      end

      def scatter_nd_sub(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterNdSub", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_nd_update(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterNdUpdate", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_sub(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterSub", [ref, indices, updates], use_locking: use_locking)
      end

      def scatter_update(ref: nil, indices: nil, updates: nil, use_locking: nil)
        Context.default.execute("ScatterUpdate", [ref, indices, updates], use_locking: use_locking)
      end

      def sdca_fprint(input: nil)
        Context.default.execute("SdcaFprint", [input])
      end

      def sdca_optimizer(sparse_example_indices: nil, sparse_feature_indices: nil, sparse_feature_values: nil, dense_features: nil, example_weights: nil, example_labels: nil, sparse_indices: nil, sparse_weights: nil, dense_weights: nil, example_state_data: nil, loss_type: nil, adaptative: nil, num_sparse_features: nil, num_sparse_features_with_values: nil, num_dense_features: nil, l1: nil, l2: nil, num_loss_partitions: nil, num_inner_iterations: nil)
        Context.default.execute("SdcaOptimizer", [sparse_example_indices, sparse_feature_indices, sparse_feature_values, dense_features, example_weights, example_labels, sparse_indices, sparse_weights, dense_weights, example_state_data], loss_type: loss_type, adaptative: adaptative, num_sparse_features: num_sparse_features, num_sparse_features_with_values: num_sparse_features_with_values, num_dense_features: num_dense_features, l1: l1, l2: l2, num_loss_partitions: num_loss_partitions, num_inner_iterations: num_inner_iterations)
      end

      def sdca_optimizer_v2(sparse_example_indices: nil, sparse_feature_indices: nil, sparse_feature_values: nil, dense_features: nil, example_weights: nil, example_labels: nil, sparse_indices: nil, sparse_weights: nil, dense_weights: nil, example_state_data: nil, loss_type: nil, adaptive: nil, num_sparse_features: nil, num_sparse_features_with_values: nil, num_dense_features: nil, l1: nil, l2: nil, num_loss_partitions: nil, num_inner_iterations: nil)
        Context.default.execute("SdcaOptimizerV2", [sparse_example_indices, sparse_feature_indices, sparse_feature_values, dense_features, example_weights, example_labels, sparse_indices, sparse_weights, dense_weights, example_state_data], loss_type: loss_type, adaptive: adaptive, num_sparse_features: num_sparse_features, num_sparse_features_with_values: num_sparse_features_with_values, num_dense_features: num_dense_features, l1: l1, l2: l2, num_loss_partitions: num_loss_partitions, num_inner_iterations: num_inner_iterations)
      end

      def sdca_shrink_l1(weights: nil, num_features: nil, l1: nil, l2: nil)
        Context.default.execute("SdcaShrinkL1", [weights], num_features: num_features, l1: l1, l2: l2)
      end

      def segment_max(data: nil, segment_ids: nil)
        Context.default.execute("SegmentMax", [data, segment_ids])
      end

      def segment_mean(data: nil, segment_ids: nil)
        Context.default.execute("SegmentMean", [data, segment_ids])
      end

      def segment_min(data: nil, segment_ids: nil)
        Context.default.execute("SegmentMin", [data, segment_ids])
      end

      def segment_prod(data: nil, segment_ids: nil)
        Context.default.execute("SegmentProd", [data, segment_ids])
      end

      def segment_sum(data: nil, segment_ids: nil)
        Context.default.execute("SegmentSum", [data, segment_ids])
      end

      def select(condition: nil, t: nil, e: nil)
        Context.default.execute("Select", [condition, t, e])
      end

      def select_v2(condition: nil, t: nil, e: nil)
        Context.default.execute("SelectV2", [condition, t, e])
      end

      def self_adjoint_eig(input: nil)
        Context.default.execute("SelfAdjointEig", [input])
      end

      def self_adjoint_eig_v2(input: nil, compute_v: nil)
        Context.default.execute("SelfAdjointEigV2", [input], compute_v: compute_v)
      end

      def selu(features: nil)
        Context.default.execute("Selu", [features])
      end

      def selu_grad(gradients: nil, outputs: nil)
        Context.default.execute("SeluGrad", [gradients, outputs])
      end

      def send_tpu_embedding_gradients(inputs: nil, learning_rates: nil, config: nil)
        Context.default.execute("SendTPUEmbeddingGradients", [inputs, learning_rates], config: config)
      end

      def serialize_iterator(resource_handle: nil)
        Context.default.execute("SerializeIterator", [resource_handle])
      end

      def serialize_many_sparse(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, out_type: nil)
        Context.default.execute("SerializeManySparse", [sparse_indices, sparse_values, sparse_shape], out_type: out_type)
      end

      def serialize_sparse(sparse_indices: nil, sparse_values: nil, sparse_shape: nil, out_type: nil)
        Context.default.execute("SerializeSparse", [sparse_indices, sparse_values, sparse_shape], out_type: out_type)
      end

      def serialize_tensor(tensor: nil)
        Context.default.execute("SerializeTensor", [tensor])
      end

      def set_size(set_indices: nil, set_values: nil, set_shape: nil, validate_indices: nil)
        Context.default.execute("SetSize", [set_indices, set_values, set_shape], validate_indices: validate_indices)
      end

      def shape(input: nil, out_type: nil)
        Context.default.execute("Shape", [input], out_type: out_type)
      end

      def shape_n(input: nil, out_type: nil)
        Context.default.execute("ShapeN", [input], out_type: out_type)
      end

      def shard_dataset(input_dataset: nil, num_shards: nil, index: nil, require_non_empty: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ShardDataset", [input_dataset, num_shards, index], require_non_empty: require_non_empty, output_types: output_types, output_shapes: output_shapes)
      end

      def sharded_filename(basename: nil, shard: nil, num_shards: nil)
        Context.default.execute("ShardedFilename", [basename, shard, num_shards])
      end

      def sharded_filespec(basename: nil, num_shards: nil)
        Context.default.execute("ShardedFilespec", [basename, num_shards])
      end

      def shuffle_and_repeat_dataset(input_dataset: nil, buffer_size: nil, seed: nil, seed2: nil, count: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ShuffleAndRepeatDataset", [input_dataset, buffer_size, seed, seed2, count], output_types: output_types, output_shapes: output_shapes)
      end

      def shuffle_dataset(input_dataset: nil, buffer_size: nil, seed: nil, seed2: nil, reshuffle_each_iteration: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ShuffleDataset", [input_dataset, buffer_size, seed, seed2], reshuffle_each_iteration: reshuffle_each_iteration, output_types: output_types, output_shapes: output_shapes)
      end

      def shutdown_distributed_tpu
        Context.default.execute("ShutdownDistributedTPU", [])
      end

      def sigmoid(x: nil)
        Context.default.execute("Sigmoid", [x])
      end

      def sigmoid_grad(y: nil, dy: nil)
        Context.default.execute("SigmoidGrad", [y, dy])
      end

      def sign(x: nil)
        Context.default.execute("Sign", [x])
      end

      def sin(x: nil)
        Context.default.execute("Sin", [x])
      end

      def sinh(x: nil)
        Context.default.execute("Sinh", [x])
      end

      def size(input: nil, out_type: nil)
        Context.default.execute("Size", [input], out_type: out_type)
      end

      def skip_dataset(input_dataset: nil, count: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("SkipDataset", [input_dataset, count], output_types: output_types, output_shapes: output_shapes)
      end

      def skipgram(filename: nil, batch_size: nil, window_size: nil, min_count: nil, subsample: nil)
        Context.default.execute("Skipgram", [], filename: filename, batch_size: batch_size, window_size: window_size, min_count: min_count, subsample: subsample)
      end

      def slice(input: nil, start: nil, size: nil)
        Context.default.execute("Slice", [input, start, size])
      end

      def snapshot(input: nil)
        Context.default.execute("Snapshot", [input])
      end

      def snapshot_dataset(input_dataset: nil, path: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("SnapshotDataset", [input_dataset, path], output_types: output_types, output_shapes: output_shapes)
      end

      def softmax(logits: nil)
        Context.default.execute("Softmax", [logits])
      end

      def softmax_cross_entropy_with_logits(features: nil, labels: nil)
        Context.default.execute("SoftmaxCrossEntropyWithLogits", [features, labels])
      end

      def softplus(features: nil)
        Context.default.execute("Softplus", [features])
      end

      def softplus_grad(gradients: nil, features: nil)
        Context.default.execute("SoftplusGrad", [gradients, features])
      end

      def softsign(features: nil)
        Context.default.execute("Softsign", [features])
      end

      def softsign_grad(gradients: nil, features: nil)
        Context.default.execute("SoftsignGrad", [gradients, features])
      end

      def space_to_batch(input: nil, paddings: nil, block_size: nil)
        Context.default.execute("SpaceToBatch", [input, paddings], block_size: block_size)
      end

      def space_to_batch_nd(input: nil, block_shape: nil, paddings: nil)
        Context.default.execute("SpaceToBatchND", [input, block_shape, paddings])
      end

      def space_to_depth(input: nil, block_size: nil, data_format: nil)
        Context.default.execute("SpaceToDepth", [input], block_size: block_size, data_format: data_format)
      end

      def sparse_accumulator_apply_gradient(handle: nil, local_step: nil, gradient_indices: nil, gradient_values: nil, gradient_shape: nil, dtype: nil, has_known_shape: nil)
        Context.default.execute("SparseAccumulatorApplyGradient", [handle, local_step, gradient_indices, gradient_values, gradient_shape], dtype: dtype, has_known_shape: has_known_shape)
      end

      def sparse_accumulator_take_gradient(handle: nil, num_required: nil, dtype: nil)
        Context.default.execute("SparseAccumulatorTakeGradient", [handle, num_required], dtype: dtype)
      end

      def sparse_add(a_indices: nil, a_values: nil, a_shape: nil, b_indices: nil, b_values: nil, b_shape: nil, thresh: nil)
        Context.default.execute("SparseAdd", [a_indices, a_values, a_shape, b_indices, b_values, b_shape, thresh])
      end

      def sparse_add_grad(backprop_val_grad: nil, a_indices: nil, b_indices: nil, sum_indices: nil)
        Context.default.execute("SparseAddGrad", [backprop_val_grad, a_indices, b_indices, sum_indices])
      end

      def sparse_apply_adadelta(var: nil, accum: nil, accum_update: nil, lr: nil, rho: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("SparseApplyAdadelta", [var, accum, accum_update, lr, rho, epsilon, grad, indices], use_locking: use_locking)
      end

      def sparse_apply_adagrad(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, use_locking: nil, update_slots: nil)
        Context.default.execute("SparseApplyAdagrad", [var, accum, lr, grad, indices], use_locking: use_locking, update_slots: update_slots)
      end

      def sparse_apply_adagrad_da(var: nil, gradient_accumulator: nil, gradient_squared_accumulator: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, global_step: nil, use_locking: nil)
        Context.default.execute("SparseApplyAdagradDA", [var, gradient_accumulator, gradient_squared_accumulator, grad, indices, lr, l1, l2, global_step], use_locking: use_locking)
      end

      def sparse_apply_centered_rms_prop(var: nil, mg: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("SparseApplyCenteredRMSProp", [var, mg, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
      end

      def sparse_apply_ftrl(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("SparseApplyFtrl", [var, accum, linear, grad, indices, lr, l1, l2, lr_power], use_locking: use_locking)
      end

      def sparse_apply_ftrl_v2(var: nil, accum: nil, linear: nil, grad: nil, indices: nil, lr: nil, l1: nil, l2: nil, l2_shrinkage: nil, lr_power: nil, use_locking: nil)
        Context.default.execute("SparseApplyFtrlV2", [var, accum, linear, grad, indices, lr, l1, l2, l2_shrinkage, lr_power], use_locking: use_locking)
      end

      def sparse_apply_momentum(var: nil, accum: nil, lr: nil, grad: nil, indices: nil, momentum: nil, use_locking: nil, use_nesterov: nil)
        Context.default.execute("SparseApplyMomentum", [var, accum, lr, grad, indices, momentum], use_locking: use_locking, use_nesterov: use_nesterov)
      end

      def sparse_apply_proximal_adagrad(var: nil, accum: nil, lr: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("SparseApplyProximalAdagrad", [var, accum, lr, l1, l2, grad, indices], use_locking: use_locking)
      end

      def sparse_apply_proximal_gradient_descent(var: nil, alpha: nil, l1: nil, l2: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("SparseApplyProximalGradientDescent", [var, alpha, l1, l2, grad, indices], use_locking: use_locking)
      end

      def sparse_apply_rms_prop(var: nil, ms: nil, mom: nil, lr: nil, rho: nil, momentum: nil, epsilon: nil, grad: nil, indices: nil, use_locking: nil)
        Context.default.execute("SparseApplyRMSProp", [var, ms, mom, lr, rho, momentum, epsilon, grad, indices], use_locking: use_locking)
      end

      def sparse_concat(indices: nil, values: nil, shapes: nil, concat_dim: nil)
        Context.default.execute("SparseConcat", [indices, values, shapes], concat_dim: concat_dim)
      end

      def sparse_conditional_accumulator(dtype: nil, shape: nil, container: nil, shared_name: nil, reduction_type: nil)
        Context.default.execute("SparseConditionalAccumulator", [], dtype: dtype, shape: shape, container: container, shared_name: shared_name, reduction_type: reduction_type)
      end

      def sparse_cross(indices: nil, values: nil, shapes: nil, dense_inputs: nil, hashed_output: nil, num_buckets: nil, hash_key: nil, sparse_types: nil, dense_types: nil, out_type: nil, internal_type: nil)
        Context.default.execute("SparseCross", [indices, values, shapes, dense_inputs], hashed_output: hashed_output, num_buckets: num_buckets, hash_key: hash_key, sparse_types: sparse_types, dense_types: dense_types, out_type: out_type, internal_type: internal_type)
      end

      def sparse_dense_cwise_add(sp_indices: nil, sp_values: nil, sp_shape: nil, dense: nil)
        Context.default.execute("SparseDenseCwiseAdd", [sp_indices, sp_values, sp_shape, dense])
      end

      def sparse_dense_cwise_div(sp_indices: nil, sp_values: nil, sp_shape: nil, dense: nil)
        Context.default.execute("SparseDenseCwiseDiv", [sp_indices, sp_values, sp_shape, dense])
      end

      def sparse_dense_cwise_mul(sp_indices: nil, sp_values: nil, sp_shape: nil, dense: nil)
        Context.default.execute("SparseDenseCwiseMul", [sp_indices, sp_values, sp_shape, dense])
      end

      def sparse_fill_empty_rows(indices: nil, values: nil, dense_shape: nil, default_value: nil)
        Context.default.execute("SparseFillEmptyRows", [indices, values, dense_shape, default_value])
      end

      def sparse_fill_empty_rows_grad(reverse_index_map: nil, grad_values: nil)
        Context.default.execute("SparseFillEmptyRowsGrad", [reverse_index_map, grad_values])
      end

      def sparse_mat_mul(a: nil, b: nil, transpose_a: nil, transpose_b: nil, a_is_sparse: nil, b_is_sparse: nil)
        Context.default.execute("SparseMatMul", [a, b], transpose_a: transpose_a, transpose_b: transpose_b, a_is_sparse: a_is_sparse, b_is_sparse: b_is_sparse)
      end

      def sparse_reduce_max(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
        Context.default.execute("SparseReduceMax", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
      end

      def sparse_reduce_max_sparse(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
        Context.default.execute("SparseReduceMaxSparse", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
      end

      def sparse_reduce_sum(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
        Context.default.execute("SparseReduceSum", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
      end

      def sparse_reduce_sum_sparse(input_indices: nil, input_values: nil, input_shape: nil, reduction_axes: nil, keep_dims: nil)
        Context.default.execute("SparseReduceSumSparse", [input_indices, input_values, input_shape, reduction_axes], keep_dims: keep_dims)
      end

      def sparse_reorder(input_indices: nil, input_values: nil, input_shape: nil)
        Context.default.execute("SparseReorder", [input_indices, input_values, input_shape])
      end

      def sparse_reshape(input_indices: nil, input_shape: nil, new_shape: nil)
        Context.default.execute("SparseReshape", [input_indices, input_shape, new_shape])
      end

      def sparse_segment_mean(data: nil, indices: nil, segment_ids: nil)
        Context.default.execute("SparseSegmentMean", [data, indices, segment_ids])
      end

      def sparse_segment_mean_grad(grad: nil, indices: nil, segment_ids: nil, output_dim0: nil)
        Context.default.execute("SparseSegmentMeanGrad", [grad, indices, segment_ids, output_dim0])
      end

      def sparse_segment_mean_with_num_segments(data: nil, indices: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("SparseSegmentMeanWithNumSegments", [data, indices, segment_ids, num_segments])
      end

      def sparse_segment_sqrt_n(data: nil, indices: nil, segment_ids: nil)
        Context.default.execute("SparseSegmentSqrtN", [data, indices, segment_ids])
      end

      def sparse_segment_sqrt_n_grad(grad: nil, indices: nil, segment_ids: nil, output_dim0: nil)
        Context.default.execute("SparseSegmentSqrtNGrad", [grad, indices, segment_ids, output_dim0])
      end

      def sparse_segment_sqrt_n_with_num_segments(data: nil, indices: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("SparseSegmentSqrtNWithNumSegments", [data, indices, segment_ids, num_segments])
      end

      def sparse_segment_sum(data: nil, indices: nil, segment_ids: nil)
        Context.default.execute("SparseSegmentSum", [data, indices, segment_ids])
      end

      def sparse_segment_sum_with_num_segments(data: nil, indices: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("SparseSegmentSumWithNumSegments", [data, indices, segment_ids, num_segments])
      end

      def sparse_slice(indices: nil, values: nil, shape: nil, start: nil, size: nil)
        Context.default.execute("SparseSlice", [indices, values, shape, start, size])
      end

      def sparse_slice_grad(backprop_val_grad: nil, input_indices: nil, input_start: nil, output_indices: nil)
        Context.default.execute("SparseSliceGrad", [backprop_val_grad, input_indices, input_start, output_indices])
      end

      def sparse_softmax(sp_indices: nil, sp_values: nil, sp_shape: nil)
        Context.default.execute("SparseSoftmax", [sp_indices, sp_values, sp_shape])
      end

      def sparse_softmax_cross_entropy_with_logits(features: nil, labels: nil)
        Context.default.execute("SparseSoftmaxCrossEntropyWithLogits", [features, labels])
      end

      def sparse_sparse_maximum(a_indices: nil, a_values: nil, a_shape: nil, b_indices: nil, b_values: nil, b_shape: nil)
        Context.default.execute("SparseSparseMaximum", [a_indices, a_values, a_shape, b_indices, b_values, b_shape])
      end

      def sparse_sparse_minimum(a_indices: nil, a_values: nil, a_shape: nil, b_indices: nil, b_values: nil, b_shape: nil)
        Context.default.execute("SparseSparseMinimum", [a_indices, a_values, a_shape, b_indices, b_values, b_shape])
      end

      def sparse_split(split_dim: nil, indices: nil, values: nil, shape: nil, num_split: nil)
        Context.default.execute("SparseSplit", [split_dim, indices, values, shape], num_split: num_split)
      end

      def sparse_tensor_dense_add(a_indices: nil, a_values: nil, a_shape: nil, b: nil)
        Context.default.execute("SparseTensorDenseAdd", [a_indices, a_values, a_shape, b])
      end

      def sparse_tensor_dense_mat_mul(a_indices: nil, a_values: nil, a_shape: nil, b: nil, adjoint_a: nil, adjoint_b: nil)
        Context.default.execute("SparseTensorDenseMatMul", [a_indices, a_values, a_shape, b], adjoint_a: adjoint_a, adjoint_b: adjoint_b)
      end

      def sparse_tensor_slice_dataset(indices: nil, values: nil, dense_shape: nil)
        Context.default.execute("SparseTensorSliceDataset", [indices, values, dense_shape])
      end

      def sparse_to_dense(sparse_indices: nil, output_shape: nil, sparse_values: nil, default_value: nil, validate_indices: nil)
        Context.default.execute("SparseToDense", [sparse_indices, output_shape, sparse_values, default_value], validate_indices: validate_indices)
      end

      def sparse_to_sparse_set_operation(set1_indices: nil, set1_values: nil, set1_shape: nil, set2_indices: nil, set2_values: nil, set2_shape: nil, set_operation: nil, validate_indices: nil)
        Context.default.execute("SparseToSparseSetOperation", [set1_indices, set1_values, set1_shape, set2_indices, set2_values, set2_shape], set_operation: set_operation, validate_indices: validate_indices)
      end

      def split(split_dim: nil, value: nil, num_split: nil)
        Context.default.execute("Split", [split_dim, value], num_split: num_split)
      end

      def split_v(value: nil, size_splits: nil, split_dim: nil, num_split: nil)
        Context.default.execute("SplitV", [value, size_splits, split_dim], num_split: num_split)
      end

      def sqrt(x: nil)
        Context.default.execute("Sqrt", [x])
      end

      def sqrt_grad(y: nil, dy: nil)
        Context.default.execute("SqrtGrad", [y, dy])
      end

      def square(x: nil)
        Context.default.execute("Square", [x])
      end

      def squared_difference(x: nil, y: nil)
        Context.default.execute("SquaredDifference", [x, y])
      end

      def squeeze(input: nil, squeeze_dims: nil)
        Context.default.execute("Squeeze", [input], squeeze_dims: squeeze_dims)
      end

      def stack(elem_type: nil, stack_name: nil)
        Context.default.execute("Stack", [], elem_type: elem_type, stack_name: stack_name)
      end

      def stack_close(handle: nil)
        Context.default.execute("StackClose", [handle])
      end

      def stack_close_v2(handle: nil)
        Context.default.execute("StackCloseV2", [handle])
      end

      def stack_pop(handle: nil, elem_type: nil)
        Context.default.execute("StackPop", [handle], elem_type: elem_type)
      end

      def stack_pop_v2(handle: nil, elem_type: nil)
        Context.default.execute("StackPopV2", [handle], elem_type: elem_type)
      end

      def stack_push(handle: nil, elem: nil, swap_memory: nil)
        Context.default.execute("StackPush", [handle, elem], swap_memory: swap_memory)
      end

      def stack_push_v2(handle: nil, elem: nil, swap_memory: nil)
        Context.default.execute("StackPushV2", [handle, elem], swap_memory: swap_memory)
      end

      def stack_v2(max_size: nil, elem_type: nil, stack_name: nil)
        Context.default.execute("StackV2", [max_size], elem_type: elem_type, stack_name: stack_name)
      end

      def stage(values: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("Stage", [values], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def stage_clear(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("StageClear", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def stage_peek(index: nil, capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("StagePeek", [index], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def stage_size(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("StageSize", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def stateful_partitioned_call(args: nil, f: nil, config: nil, config_proto: nil, executor_type: nil)
        Context.default.execute("StatefulPartitionedCall", [args], f: f, config: config, config_proto: config_proto, executor_type: executor_type)
      end

      def stateful_random_binomial(resource: nil, algorithm: nil, shape: nil, counts: nil, probs: nil, dtype: nil)
        Context.default.execute("StatefulRandomBinomial", [resource, algorithm, shape, counts, probs], dtype: dtype)
      end

      def stateful_standard_normal(resource: nil, shape: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("StatefulStandardNormal", [resource, shape], dtype: dtype, shape_dtype: shape_dtype)
      end

      def stateful_standard_normal_v2(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("StatefulStandardNormalV2", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
      end

      def stateful_truncated_normal(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("StatefulTruncatedNormal", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
      end

      def stateful_uniform(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("StatefulUniform", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
      end

      def stateful_uniform_full_int(resource: nil, algorithm: nil, shape: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("StatefulUniformFullInt", [resource, algorithm, shape], dtype: dtype, shape_dtype: shape_dtype)
      end

      def stateful_uniform_int(resource: nil, algorithm: nil, shape: nil, minval: nil, maxval: nil, dtype: nil, shape_dtype: nil)
        Context.default.execute("StatefulUniformInt", [resource, algorithm, shape, minval, maxval], dtype: dtype, shape_dtype: shape_dtype)
      end

      def stateless_if(cond: nil, input: nil, then_branch: nil, else_branch: nil)
        Context.default.execute("StatelessIf", [cond, input], then_branch: then_branch, else_branch: else_branch)
      end

      def stateless_multinomial(logits: nil, num_samples: nil, seed: nil, output_dtype: nil)
        Context.default.execute("StatelessMultinomial", [logits, num_samples, seed], output_dtype: output_dtype)
      end

      def stateless_random_normal(shape: nil, seed: nil, dtype: nil)
        Context.default.execute("StatelessRandomNormal", [shape, seed], dtype: dtype)
      end

      def stateless_random_uniform(shape: nil, seed: nil, dtype: nil)
        Context.default.execute("StatelessRandomUniform", [shape, seed], dtype: dtype)
      end

      def stateless_random_uniform_int(shape: nil, seed: nil, minval: nil, maxval: nil, dtype: nil)
        Context.default.execute("StatelessRandomUniformInt", [shape, seed, minval, maxval], dtype: dtype)
      end

      def stateless_truncated_normal(shape: nil, seed: nil, dtype: nil)
        Context.default.execute("StatelessTruncatedNormal", [shape, seed], dtype: dtype)
      end

      def stateless_while(input: nil, cond: nil, body: nil)
        Context.default.execute("StatelessWhile", [input], cond: cond, body: body)
      end

      def static_regex_full_match(input: nil, pattern: nil)
        Context.default.execute("StaticRegexFullMatch", [input], pattern: pattern)
      end

      def static_regex_replace(input: nil, pattern: nil, rewrite: nil, replace_global: nil)
        Context.default.execute("StaticRegexReplace", [input], pattern: pattern, rewrite: rewrite, replace_global: replace_global)
      end

      def stats_aggregator_handle_v2(container: nil, shared_name: nil)
        Context.default.execute("StatsAggregatorHandleV2", [], container: container, shared_name: shared_name)
      end

      def stats_aggregator_set_summary_writer(stats_aggregator: nil, summary: nil)
        Context.default.execute("StatsAggregatorSetSummaryWriter", [stats_aggregator, summary])
      end

      def stop_gradient(input: nil)
        Context.default.execute("StopGradient", [input])
      end

      def strided_slice(input: nil, start: nil, stop: nil, strides: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
        Context.default.execute("StridedSlice", [input, start, stop, strides], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
      end

      def strided_slice_assign(ref: nil, start: nil, stop: nil, strides: nil, value: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
        Context.default.execute("StridedSliceAssign", [ref, start, stop, strides, value], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
      end

      def strided_slice_grad(shape: nil, start: nil, stop: nil, strides: nil, dy: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
        Context.default.execute("StridedSliceGrad", [shape, start, stop, strides, dy], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
      end

      def string_format(inputs: nil, template: nil, placeholder: nil, summarize: nil)
        Context.default.execute("StringFormat", [inputs], template: template, placeholder: placeholder, summarize: summarize)
      end

      def string_join(inputs: nil, separator: nil)
        Context.default.execute("StringJoin", [inputs], separator: separator)
      end

      def string_length(input: nil, unit: nil)
        Context.default.execute("StringLength", [input], unit: unit)
      end

      def string_lower(input: nil, encoding: nil)
        Context.default.execute("StringLower", [input], encoding: encoding)
      end

      def string_split(input: nil, delimiter: nil, skip_empty: nil)
        Context.default.execute("StringSplit", [input, delimiter], skip_empty: skip_empty)
      end

      def string_split_v2(input: nil, sep: nil, maxsplit: nil)
        Context.default.execute("StringSplitV2", [input, sep], maxsplit: maxsplit)
      end

      def string_strip(input: nil)
        Context.default.execute("StringStrip", [input])
      end

      def string_to_hash_bucket(string_tensor: nil, num_buckets: nil)
        Context.default.execute("StringToHashBucket", [string_tensor], num_buckets: num_buckets)
      end

      def string_to_hash_bucket_fast(input: nil, num_buckets: nil)
        Context.default.execute("StringToHashBucketFast", [input], num_buckets: num_buckets)
      end

      def string_to_hash_bucket_strong(input: nil, num_buckets: nil, key: nil)
        Context.default.execute("StringToHashBucketStrong", [input], num_buckets: num_buckets, key: key)
      end

      def string_to_number(string_tensor: nil, out_type: nil)
        Context.default.execute("StringToNumber", [string_tensor], out_type: out_type)
      end

      def string_upper(input: nil, encoding: nil)
        Context.default.execute("StringUpper", [input], encoding: encoding)
      end

      def sub(x: nil, y: nil)
        Context.default.execute("Sub", [x, y])
      end

      def substr(input: nil, pos: nil, len: nil, unit: nil)
        Context.default.execute("Substr", [input, pos, len], unit: unit)
      end

      def sum(input: nil, reduction_indices: nil, keep_dims: nil)
        Context.default.execute("Sum", [input, reduction_indices], keep_dims: keep_dims)
      end

      def summary_writer(shared_name: nil, container: nil)
        Context.default.execute("SummaryWriter", [], shared_name: shared_name, container: container)
      end

      def svd(input: nil, compute_uv: nil, full_matrices: nil)
        Context.default.execute("Svd", [input], compute_uv: compute_uv, full_matrices: full_matrices)
      end

      def switch(data: nil, pred: nil)
        Context.default.execute("Switch", [data, pred])
      end

      def symbolic_gradient(input: nil, f: nil)
        Context.default.execute("SymbolicGradient", [input], f: f)
      end

      def tf_record_dataset(filenames: nil, compression_type: nil, buffer_size: nil)
        Context.default.execute("TFRecordDataset", [filenames, compression_type, buffer_size])
      end

      def tf_record_reader(container: nil, shared_name: nil, compression_type: nil)
        Context.default.execute("TFRecordReader", [], container: container, shared_name: shared_name, compression_type: compression_type)
      end

      def tf_record_reader_v2(container: nil, shared_name: nil, compression_type: nil)
        Context.default.execute("TFRecordReaderV2", [], container: container, shared_name: shared_name, compression_type: compression_type)
      end

      def tpu_compilation_result
        Context.default.execute("TPUCompilationResult", [])
      end

      def tpu_embedding_activations(embedding_variable: nil, sliced_activations: nil, table_id: nil, lookup_id: nil)
        Context.default.execute("TPUEmbeddingActivations", [embedding_variable, sliced_activations], table_id: table_id, lookup_id: lookup_id)
      end

      def tpu_ordinal_selector
        Context.default.execute("TPUOrdinalSelector", [])
      end

      def tpu_partitioned_call(args: nil, device_ordinal: nil, f: nil)
        Context.default.execute("TPUPartitionedCall", [args, device_ordinal], f: f)
      end

      def tpu_replicate_metadata(num_replicas: nil, num_cores_per_replica: nil, topology: nil, use_tpu: nil, device_assignment: nil, computation_shape: nil, host_compute_core: nil, padding_map: nil, step_marker_location: nil)
        Context.default.execute("TPUReplicateMetadata", [], num_replicas: num_replicas, num_cores_per_replica: num_cores_per_replica, topology: topology, use_tpu: use_tpu, device_assignment: device_assignment, computation_shape: computation_shape, host_compute_core: host_compute_core, padding_map: padding_map, step_marker_location: step_marker_location)
      end

      def tpu_replicated_input(inputs: nil)
        Context.default.execute("TPUReplicatedInput", [inputs])
      end

      def tpu_replicated_output(input: nil, num_replicas: nil)
        Context.default.execute("TPUReplicatedOutput", [input], num_replicas: num_replicas)
      end

      def take_dataset(input_dataset: nil, count: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("TakeDataset", [input_dataset, count], output_types: output_types, output_shapes: output_shapes)
      end

      def take_many_sparse_from_tensors_map(sparse_handles: nil, dtype: nil, container: nil, shared_name: nil)
        Context.default.execute("TakeManySparseFromTensorsMap", [sparse_handles], dtype: dtype, container: container, shared_name: shared_name)
      end

      def tan(x: nil)
        Context.default.execute("Tan", [x])
      end

      def tanh(x: nil)
        Context.default.execute("Tanh", [x])
      end

      def tanh_grad(y: nil, dy: nil)
        Context.default.execute("TanhGrad", [y, dy])
      end

      def temporary_variable(shape: nil, dtype: nil, var_name: nil)
        Context.default.execute("TemporaryVariable", [], shape: shape, dtype: dtype, var_name: var_name)
      end

      def tensor_array(size: nil, dtype: nil, dynamic_size: nil, clear_after_read: nil, tensor_array_name: nil, element_shape: nil)
        Context.default.execute("TensorArray", [size], dtype: dtype, dynamic_size: dynamic_size, clear_after_read: clear_after_read, tensor_array_name: tensor_array_name, element_shape: element_shape)
      end

      def tensor_array_close(handle: nil)
        Context.default.execute("TensorArrayClose", [handle])
      end

      def tensor_array_close_v2(handle: nil)
        Context.default.execute("TensorArrayCloseV2", [handle])
      end

      def tensor_array_close_v3(handle: nil)
        Context.default.execute("TensorArrayCloseV3", [handle])
      end

      def tensor_array_concat(handle: nil, flow_in: nil, dtype: nil, element_shape_except0: nil)
        Context.default.execute("TensorArrayConcat", [handle, flow_in], dtype: dtype, element_shape_except0: element_shape_except0)
      end

      def tensor_array_concat_v2(handle: nil, flow_in: nil, dtype: nil, element_shape_except0: nil)
        Context.default.execute("TensorArrayConcatV2", [handle, flow_in], dtype: dtype, element_shape_except0: element_shape_except0)
      end

      def tensor_array_concat_v3(handle: nil, flow_in: nil, dtype: nil, element_shape_except0: nil)
        Context.default.execute("TensorArrayConcatV3", [handle, flow_in], dtype: dtype, element_shape_except0: element_shape_except0)
      end

      def tensor_array_gather(handle: nil, indices: nil, flow_in: nil, dtype: nil, element_shape: nil)
        Context.default.execute("TensorArrayGather", [handle, indices, flow_in], dtype: dtype, element_shape: element_shape)
      end

      def tensor_array_gather_v2(handle: nil, indices: nil, flow_in: nil, dtype: nil, element_shape: nil)
        Context.default.execute("TensorArrayGatherV2", [handle, indices, flow_in], dtype: dtype, element_shape: element_shape)
      end

      def tensor_array_gather_v3(handle: nil, indices: nil, flow_in: nil, dtype: nil, element_shape: nil)
        Context.default.execute("TensorArrayGatherV3", [handle, indices, flow_in], dtype: dtype, element_shape: element_shape)
      end

      def tensor_array_grad(handle: nil, flow_in: nil, source: nil)
        Context.default.execute("TensorArrayGrad", [handle, flow_in], source: source)
      end

      def tensor_array_grad_v2(handle: nil, flow_in: nil, source: nil)
        Context.default.execute("TensorArrayGradV2", [handle, flow_in], source: source)
      end

      def tensor_array_grad_v3(handle: nil, flow_in: nil, source: nil)
        Context.default.execute("TensorArrayGradV3", [handle, flow_in], source: source)
      end

      def tensor_array_grad_with_shape(handle: nil, flow_in: nil, shape_to_prepend: nil, source: nil)
        Context.default.execute("TensorArrayGradWithShape", [handle, flow_in, shape_to_prepend], source: source)
      end

      def tensor_array_pack(handle: nil, flow_in: nil, dtype: nil, element_shape: nil)
        Context.default.execute("TensorArrayPack", [handle, flow_in], dtype: dtype, element_shape: element_shape)
      end

      def tensor_array_read(handle: nil, index: nil, flow_in: nil, dtype: nil)
        Context.default.execute("TensorArrayRead", [handle, index, flow_in], dtype: dtype)
      end

      def tensor_array_read_v2(handle: nil, index: nil, flow_in: nil, dtype: nil)
        Context.default.execute("TensorArrayReadV2", [handle, index, flow_in], dtype: dtype)
      end

      def tensor_array_read_v3(handle: nil, index: nil, flow_in: nil, dtype: nil)
        Context.default.execute("TensorArrayReadV3", [handle, index, flow_in], dtype: dtype)
      end

      def tensor_array_scatter(handle: nil, indices: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayScatter", [handle, indices, value, flow_in])
      end

      def tensor_array_scatter_v2(handle: nil, indices: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayScatterV2", [handle, indices, value, flow_in])
      end

      def tensor_array_scatter_v3(handle: nil, indices: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayScatterV3", [handle, indices, value, flow_in])
      end

      def tensor_array_size(handle: nil, flow_in: nil)
        Context.default.execute("TensorArraySize", [handle, flow_in])
      end

      def tensor_array_size_v2(handle: nil, flow_in: nil)
        Context.default.execute("TensorArraySizeV2", [handle, flow_in])
      end

      def tensor_array_size_v3(handle: nil, flow_in: nil)
        Context.default.execute("TensorArraySizeV3", [handle, flow_in])
      end

      def tensor_array_split(handle: nil, value: nil, lengths: nil, flow_in: nil)
        Context.default.execute("TensorArraySplit", [handle, value, lengths, flow_in])
      end

      def tensor_array_split_v2(handle: nil, value: nil, lengths: nil, flow_in: nil)
        Context.default.execute("TensorArraySplitV2", [handle, value, lengths, flow_in])
      end

      def tensor_array_split_v3(handle: nil, value: nil, lengths: nil, flow_in: nil)
        Context.default.execute("TensorArraySplitV3", [handle, value, lengths, flow_in])
      end

      def tensor_array_unpack(handle: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayUnpack", [handle, value, flow_in])
      end

      def tensor_array_v2(size: nil, dtype: nil, element_shape: nil, dynamic_size: nil, clear_after_read: nil, tensor_array_name: nil)
        Context.default.execute("TensorArrayV2", [size], dtype: dtype, element_shape: element_shape, dynamic_size: dynamic_size, clear_after_read: clear_after_read, tensor_array_name: tensor_array_name)
      end

      def tensor_array_v3(size: nil, dtype: nil, element_shape: nil, dynamic_size: nil, clear_after_read: nil, identical_element_shapes: nil, tensor_array_name: nil)
        Context.default.execute("TensorArrayV3", [size], dtype: dtype, element_shape: element_shape, dynamic_size: dynamic_size, clear_after_read: clear_after_read, identical_element_shapes: identical_element_shapes, tensor_array_name: tensor_array_name)
      end

      def tensor_array_write(handle: nil, index: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayWrite", [handle, index, value, flow_in])
      end

      def tensor_array_write_v2(handle: nil, index: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayWriteV2", [handle, index, value, flow_in])
      end

      def tensor_array_write_v3(handle: nil, index: nil, value: nil, flow_in: nil)
        Context.default.execute("TensorArrayWriteV3", [handle, index, value, flow_in])
      end

      def tensor_dataset(components: nil, output_shapes: nil)
        Context.default.execute("TensorDataset", [components], output_shapes: output_shapes)
      end

      def tensor_forest_create_tree_variable(tree_handle: nil, tree_config: nil)
        Context.default.execute("TensorForestCreateTreeVariable", [tree_handle, tree_config])
      end

      def tensor_forest_tree_deserialize(tree_handle: nil, tree_config: nil)
        Context.default.execute("TensorForestTreeDeserialize", [tree_handle, tree_config])
      end

      def tensor_forest_tree_is_initialized_op(tree_handle: nil)
        Context.default.execute("TensorForestTreeIsInitializedOp", [tree_handle])
      end

      def tensor_forest_tree_predict(tree_handle: nil, dense_features: nil, logits_dimension: nil)
        Context.default.execute("TensorForestTreePredict", [tree_handle, dense_features], logits_dimension: logits_dimension)
      end

      def tensor_forest_tree_resource_handle_op(container: nil, shared_name: nil)
        Context.default.execute("TensorForestTreeResourceHandleOp", [], container: container, shared_name: shared_name)
      end

      def tensor_forest_tree_serialize(tree_handle: nil)
        Context.default.execute("TensorForestTreeSerialize", [tree_handle])
      end

      def tensor_forest_tree_size(tree_handle: nil)
        Context.default.execute("TensorForestTreeSize", [tree_handle])
      end

      def tensor_list_concat(input_handle: nil, element_dtype: nil, element_shape: nil)
        Context.default.execute("TensorListConcat", [input_handle], element_dtype: element_dtype, element_shape: element_shape)
      end

      def tensor_list_concat_lists(input_a: nil, input_b: nil, element_dtype: nil)
        Context.default.execute("TensorListConcatLists", [input_a, input_b], element_dtype: element_dtype)
      end

      def tensor_list_concat_v2(input_handle: nil, element_shape: nil, leading_dims: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("TensorListConcatV2", [input_handle, element_shape, leading_dims], element_dtype: element_dtype, shape_type: shape_type)
      end

      def tensor_list_element_shape(input_handle: nil, shape_type: nil)
        Context.default.execute("TensorListElementShape", [input_handle], shape_type: shape_type)
      end

      def tensor_list_from_tensor(tensor: nil, element_shape: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("TensorListFromTensor", [tensor, element_shape], element_dtype: element_dtype, shape_type: shape_type)
      end

      def tensor_list_gather(input_handle: nil, indices: nil, element_shape: nil, element_dtype: nil)
        Context.default.execute("TensorListGather", [input_handle, indices, element_shape], element_dtype: element_dtype)
      end

      def tensor_list_get_item(input_handle: nil, index: nil, element_shape: nil, element_dtype: nil)
        Context.default.execute("TensorListGetItem", [input_handle, index, element_shape], element_dtype: element_dtype)
      end

      def tensor_list_length(input_handle: nil)
        Context.default.execute("TensorListLength", [input_handle])
      end

      def tensor_list_pop_back(input_handle: nil, element_shape: nil, element_dtype: nil)
        Context.default.execute("TensorListPopBack", [input_handle, element_shape], element_dtype: element_dtype)
      end

      def tensor_list_push_back(input_handle: nil, tensor: nil, element_dtype: nil)
        Context.default.execute("TensorListPushBack", [input_handle, tensor], element_dtype: element_dtype)
      end

      def tensor_list_push_back_batch(input_handles: nil, tensor: nil, element_dtype: nil)
        Context.default.execute("TensorListPushBackBatch", [input_handles, tensor], element_dtype: element_dtype)
      end

      def tensor_list_reserve(element_shape: nil, num_elements: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("TensorListReserve", [element_shape, num_elements], element_dtype: element_dtype, shape_type: shape_type)
      end

      def tensor_list_resize(input_handle: nil, size: nil)
        Context.default.execute("TensorListResize", [input_handle, size])
      end

      def tensor_list_scatter(tensor: nil, indices: nil, element_shape: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("TensorListScatter", [tensor, indices, element_shape], element_dtype: element_dtype, shape_type: shape_type)
      end

      def tensor_list_scatter_into_existing_list(input_handle: nil, tensor: nil, indices: nil, element_dtype: nil)
        Context.default.execute("TensorListScatterIntoExistingList", [input_handle, tensor, indices], element_dtype: element_dtype)
      end

      def tensor_list_scatter_v2(tensor: nil, indices: nil, element_shape: nil, num_elements: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("TensorListScatterV2", [tensor, indices, element_shape, num_elements], element_dtype: element_dtype, shape_type: shape_type)
      end

      def tensor_list_set_item(input_handle: nil, index: nil, item: nil, element_dtype: nil)
        Context.default.execute("TensorListSetItem", [input_handle, index, item], element_dtype: element_dtype)
      end

      def tensor_list_split(tensor: nil, element_shape: nil, lengths: nil, element_dtype: nil, shape_type: nil)
        Context.default.execute("TensorListSplit", [tensor, element_shape, lengths], element_dtype: element_dtype, shape_type: shape_type)
      end

      def tensor_list_stack(input_handle: nil, element_shape: nil, element_dtype: nil, num_elements: nil)
        Context.default.execute("TensorListStack", [input_handle, element_shape], element_dtype: element_dtype, num_elements: num_elements)
      end

      def tensor_scatter_add(tensor: nil, indices: nil, updates: nil)
        Context.default.execute("TensorScatterAdd", [tensor, indices, updates])
      end

      def tensor_scatter_sub(tensor: nil, indices: nil, updates: nil)
        Context.default.execute("TensorScatterSub", [tensor, indices, updates])
      end

      def tensor_scatter_update(tensor: nil, indices: nil, updates: nil)
        Context.default.execute("TensorScatterUpdate", [tensor, indices, updates])
      end

      def tensor_slice_dataset(components: nil, output_shapes: nil)
        Context.default.execute("TensorSliceDataset", [components], output_shapes: output_shapes)
      end

      def tensor_strided_slice_update(input: nil, start: nil, stop: nil, strides: nil, value: nil, begin_mask: nil, end_mask: nil, ellipsis_mask: nil, new_axis_mask: nil, shrink_axis_mask: nil)
        Context.default.execute("TensorStridedSliceUpdate", [input, start, stop, strides, value], begin_mask: begin_mask, end_mask: end_mask, ellipsis_mask: ellipsis_mask, new_axis_mask: new_axis_mask, shrink_axis_mask: shrink_axis_mask)
      end

      def tensor_summary(tensor: nil, description: nil, labels: nil, display_name: nil)
        Context.default.execute("TensorSummary", [tensor], description: description, labels: labels, display_name: display_name)
      end

      def tensor_summary_v2(tag: nil, tensor: nil, serialized_summary_metadata: nil)
        Context.default.execute("TensorSummaryV2", [tag, tensor, serialized_summary_metadata])
      end

      def text_line_dataset(filenames: nil, compression_type: nil, buffer_size: nil)
        Context.default.execute("TextLineDataset", [filenames, compression_type, buffer_size])
      end

      def text_line_reader(skip_header_lines: nil, container: nil, shared_name: nil)
        Context.default.execute("TextLineReader", [], skip_header_lines: skip_header_lines, container: container, shared_name: shared_name)
      end

      def text_line_reader_v2(skip_header_lines: nil, container: nil, shared_name: nil)
        Context.default.execute("TextLineReaderV2", [], skip_header_lines: skip_header_lines, container: container, shared_name: shared_name)
      end

      def thread_unsafe_unigram_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
        Context.default.execute("ThreadUnsafeUnigramCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
      end

      def tile(input: nil, multiples: nil)
        Context.default.execute("Tile", [input, multiples])
      end

      def tile_grad(input: nil, multiples: nil)
        Context.default.execute("TileGrad", [input, multiples])
      end

      def timestamp
        Context.default.execute("Timestamp", [])
      end

      def top_k(input: nil, k: nil, sorted: nil)
        Context.default.execute("TopK", [input], k: k, sorted: sorted)
      end

      def top_kv2(input: nil, k: nil, sorted: nil)
        Context.default.execute("TopKV2", [input, k], sorted: sorted)
      end

      def transpose(x: nil, perm: nil)
        Context.default.execute("Transpose", [x, perm])
      end

      def tridiagonal_mat_mul(superdiag: nil, maindiag: nil, subdiag: nil, rhs: nil)
        Context.default.execute("TridiagonalMatMul", [superdiag, maindiag, subdiag, rhs])
      end

      def tridiagonal_solve(diagonals: nil, rhs: nil, partial_pivoting: nil)
        Context.default.execute("TridiagonalSolve", [diagonals, rhs], partial_pivoting: partial_pivoting)
      end

      def truncate_div(x: nil, y: nil)
        Context.default.execute("TruncateDiv", [x, y])
      end

      def truncate_mod(x: nil, y: nil)
        Context.default.execute("TruncateMod", [x, y])
      end

      def truncated_normal(shape: nil, seed: nil, seed2: nil, dtype: nil)
        Context.default.execute("TruncatedNormal", [shape], seed: seed, seed2: seed2, dtype: dtype)
      end

      def try_rpc(address: nil, method: nil, request: nil, protocol: nil, fail_fast: nil, timeout_in_ms: nil)
        Context.default.execute("TryRpc", [address, method, request], protocol: protocol, fail_fast: fail_fast, timeout_in_ms: timeout_in_ms)
      end

      def unbatch(batched_tensor: nil, batch_index: nil, id: nil, timeout_micros: nil, container: nil, shared_name: nil)
        Context.default.execute("Unbatch", [batched_tensor, batch_index, id], timeout_micros: timeout_micros, container: container, shared_name: shared_name)
      end

      def unbatch_grad(original_input: nil, batch_index: nil, grad: nil, id: nil, container: nil, shared_name: nil)
        Context.default.execute("UnbatchGrad", [original_input, batch_index, grad, id], container: container, shared_name: shared_name)
      end

      def unicode_decode(input: nil, input_encoding: nil, errors: nil, replacement_char: nil, replace_control_characters: nil)
        Context.default.execute("UnicodeDecode", [input], input_encoding: input_encoding, errors: errors, replacement_char: replacement_char, replace_control_characters: replace_control_characters)
      end

      def unicode_decode_with_offsets(input: nil, input_encoding: nil, errors: nil, replacement_char: nil, replace_control_characters: nil)
        Context.default.execute("UnicodeDecodeWithOffsets", [input], input_encoding: input_encoding, errors: errors, replacement_char: replacement_char, replace_control_characters: replace_control_characters)
      end

      def unicode_encode(input_values: nil, input_splits: nil, errors: nil, output_encoding: nil, replacement_char: nil)
        Context.default.execute("UnicodeEncode", [input_values, input_splits], errors: errors, output_encoding: output_encoding, replacement_char: replacement_char)
      end

      def unicode_script(input: nil)
        Context.default.execute("UnicodeScript", [input])
      end

      def unicode_transcode(input: nil, input_encoding: nil, output_encoding: nil, errors: nil, replacement_char: nil, replace_control_characters: nil)
        Context.default.execute("UnicodeTranscode", [input], input_encoding: input_encoding, output_encoding: output_encoding, errors: errors, replacement_char: replacement_char, replace_control_characters: replace_control_characters)
      end

      def uniform_candidate_sampler(true_classes: nil, num_true: nil, num_sampled: nil, unique: nil, range_max: nil, seed: nil, seed2: nil)
        Context.default.execute("UniformCandidateSampler", [true_classes], num_true: num_true, num_sampled: num_sampled, unique: unique, range_max: range_max, seed: seed, seed2: seed2)
      end

      def unique(x: nil, out_idx: nil)
        Context.default.execute("Unique", [x], out_idx: out_idx)
      end

      def unique_v2(x: nil, axis: nil, out_idx: nil)
        Context.default.execute("UniqueV2", [x, axis], out_idx: out_idx)
      end

      def unique_with_counts(x: nil, out_idx: nil)
        Context.default.execute("UniqueWithCounts", [x], out_idx: out_idx)
      end

      def unique_with_counts_v2(x: nil, axis: nil, out_idx: nil)
        Context.default.execute("UniqueWithCountsV2", [x, axis], out_idx: out_idx)
      end

      def unpack(value: nil, num: nil, axis: nil)
        Context.default.execute("Unpack", [value], num: num, axis: axis)
      end

      def unravel_index(indices: nil, dims: nil)
        Context.default.execute("UnravelIndex", [indices, dims])
      end

      def unsorted_segment_max(data: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("UnsortedSegmentMax", [data, segment_ids, num_segments])
      end

      def unsorted_segment_min(data: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("UnsortedSegmentMin", [data, segment_ids, num_segments])
      end

      def unsorted_segment_prod(data: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("UnsortedSegmentProd", [data, segment_ids, num_segments])
      end

      def unsorted_segment_sum(data: nil, segment_ids: nil, num_segments: nil)
        Context.default.execute("UnsortedSegmentSum", [data, segment_ids, num_segments])
      end

      def unstage(capacity: nil, memory_limit: nil, dtypes: nil, container: nil, shared_name: nil)
        Context.default.execute("Unstage", [], capacity: capacity, memory_limit: memory_limit, dtypes: dtypes, container: container, shared_name: shared_name)
      end

      def unwrap_dataset_variant(input_handle: nil)
        Context.default.execute("UnwrapDatasetVariant", [input_handle])
      end

      def upper_bound(sorted_inputs: nil, values: nil, out_type: nil)
        Context.default.execute("UpperBound", [sorted_inputs, values], out_type: out_type)
      end

      def var_handle_op(container: nil, shared_name: nil, dtype: nil, shape: nil)
        Context.default.execute("VarHandleOp", [], container: container, shared_name: shared_name, dtype: dtype, shape: shape)
      end

      def var_is_initialized_op(resource: nil)
        Context.default.execute("VarIsInitializedOp", [resource])
      end

      def variable(shape: nil, dtype: nil, container: nil, shared_name: nil)
        Context.default.execute("Variable", [], shape: shape, dtype: dtype, container: container, shared_name: shared_name)
      end

      def variable_shape(input: nil, out_type: nil)
        Context.default.execute("VariableShape", [input], out_type: out_type)
      end

      def variable_v2(shape: nil, dtype: nil, container: nil, shared_name: nil)
        Context.default.execute("VariableV2", [], shape: shape, dtype: dtype, container: container, shared_name: shared_name)
      end

      def where(input: nil)
        Context.default.execute("Where", [input])
      end

      def while(input: nil, cond: nil, body: nil, output_shapes: nil, parallel_iterations: nil)
        Context.default.execute("While", [input], cond: cond, body: body, output_shapes: output_shapes, parallel_iterations: parallel_iterations)
      end

      def whole_file_reader(container: nil, shared_name: nil)
        Context.default.execute("WholeFileReader", [], container: container, shared_name: shared_name)
      end

      def whole_file_reader_v2(container: nil, shared_name: nil)
        Context.default.execute("WholeFileReaderV2", [], container: container, shared_name: shared_name)
      end

      def window_dataset(input_dataset: nil, size: nil, shift: nil, stride: nil, drop_remainder: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("WindowDataset", [input_dataset, size, shift, stride, drop_remainder], output_types: output_types, output_shapes: output_shapes)
      end

      def worker_heartbeat(request: nil)
        Context.default.execute("WorkerHeartbeat", [request])
      end

      def wrap_dataset_variant(input_handle: nil)
        Context.default.execute("WrapDatasetVariant", [input_handle])
      end

      def write_audio_summary(writer: nil, step: nil, tag: nil, tensor: nil, sample_rate: nil, max_outputs: nil)
        Context.default.execute("WriteAudioSummary", [writer, step, tag, tensor, sample_rate], max_outputs: max_outputs)
      end

      def write_file(filename: nil, contents: nil)
        Context.default.execute("WriteFile", [filename, contents])
      end

      def write_graph_summary(writer: nil, step: nil, tensor: nil)
        Context.default.execute("WriteGraphSummary", [writer, step, tensor])
      end

      def write_histogram_summary(writer: nil, step: nil, tag: nil, values: nil)
        Context.default.execute("WriteHistogramSummary", [writer, step, tag, values])
      end

      def write_image_summary(writer: nil, step: nil, tag: nil, tensor: nil, bad_color: nil, max_images: nil)
        Context.default.execute("WriteImageSummary", [writer, step, tag, tensor, bad_color], max_images: max_images)
      end

      def write_raw_proto_summary(writer: nil, step: nil, tensor: nil)
        Context.default.execute("WriteRawProtoSummary", [writer, step, tensor])
      end

      def write_scalar_summary(writer: nil, step: nil, tag: nil, value: nil)
        Context.default.execute("WriteScalarSummary", [writer, step, tag, value])
      end

      def write_summary(writer: nil, step: nil, tensor: nil, tag: nil, summary_metadata: nil)
        Context.default.execute("WriteSummary", [writer, step, tensor, tag, summary_metadata])
      end

      def xdivy(x: nil, y: nil)
        Context.default.execute("Xdivy", [x, y])
      end

      def xlogy(x: nil, y: nil)
        Context.default.execute("Xlogy", [x, y])
      end

      def zeros_like(x: nil)
        Context.default.execute("ZerosLike", [x])
      end

      def zeta(x: nil, q: nil)
        Context.default.execute("Zeta", [x, q])
      end

      def zip_dataset(input_datasets: nil, output_types: nil, output_shapes: nil)
        Context.default.execute("ZipDataset", [input_datasets], output_types: output_types, output_shapes: output_shapes, N: input_datasets.length)
      end
    end
  end
end
